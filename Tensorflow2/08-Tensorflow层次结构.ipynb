{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow层次结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-12T00:45:41.779143Z",
     "iopub.status.busy": "2020-06-12T00:45:41.778558Z",
     "iopub.status.idle": "2020-06-12T00:45:43.428424Z",
     "shell.execute_reply": "2020-06-12T00:45:43.427618Z",
     "shell.execute_reply.started": "2020-06-12T00:45:41.779074Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# from tensorflow.keras import layers\n",
    "# from tensorflow.keras import losses\n",
    "# from tensorflow.keras import metrics\n",
    "# from tensorflow.keras import optimizers\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 低层API示例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**低阶API** 主要包括**张量操作**，**计算图** 和 **自动微分** 等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-12T00:45:43.429773Z",
     "iopub.status.busy": "2020-06-12T00:45:43.429598Z",
     "iopub.status.idle": "2020-06-12T00:45:43.437490Z",
     "shell.execute_reply": "2020-06-12T00:45:43.436549Z",
     "shell.execute_reply.started": "2020-06-12T00:45:43.429748Z"
    }
   },
   "outputs": [],
   "source": [
    "#打印时间分割线\n",
    "@tf.function\n",
    "def printbar():\n",
    "    ts = tf.timestamp()\n",
    "    today_ts = ts % (24 * 60 * 60)\n",
    "\n",
    "    hour = tf.cast(today_ts // 3600 + 8, tf.int32) % tf.constant(24)\n",
    "    minite = tf.cast((today_ts % 3600) // 60, tf.int32)\n",
    "    second = tf.cast(tf.floor(today_ts % 60), tf.int32)\n",
    "\n",
    "    def timeformat(m):\n",
    "        if tf.strings.length(tf.strings.format(\"{}\", m))==1:\n",
    "            return(tf.strings.format(\"0{}\", m))\n",
    "        else:\n",
    "            return(tf.strings.format(\"{}\", m))\n",
    "\n",
    "    timestring = tf.strings.join([timeformat(hour), timeformat(minite), timeformat(second)], separator = \":\")\n",
    "    \n",
    "    tf.print(\"=\" * 10, end = \"\")\n",
    "    tf.print(timestring, end = \"\")\n",
    "    tf.print(\"=\" * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-12T00:45:43.438958Z",
     "iopub.status.busy": "2020-06-12T00:45:43.438768Z",
     "iopub.status.idle": "2020-06-12T00:45:48.515877Z",
     "shell.execute_reply": "2020-06-12T00:45:48.515036Z",
     "shell.execute_reply.started": "2020-06-12T00:45:43.438936Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========08:45:48==========\n"
     ]
    }
   ],
   "source": [
    "s = printbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-12T00:45:48.517662Z",
     "iopub.status.busy": "2020-06-12T00:45:48.517429Z",
     "iopub.status.idle": "2020-06-12T00:45:48.527484Z",
     "shell.execute_reply": "2020-06-12T00:45:48.526745Z",
     "shell.execute_reply.started": "2020-06-12T00:45:48.517629Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape = (400, 2)\n",
      "X head =\n",
      "[[ 8.564583    0.20936203]\n",
      " [-5.2583647  -8.474501  ]\n",
      " [-4.7962046  -2.2101355 ]\n",
      " [ 1.8256903   5.8592415 ]\n",
      " [-4.295366   -8.950251  ]\n",
      " [-4.0162992  -1.1756468 ]\n",
      " [-1.6190863   5.7091694 ]\n",
      " [ 2.7599125   2.6526718 ]\n",
      " [ 5.211215    4.967573  ]\n",
      " [ 3.4571533  -7.957039  ]]\n",
      "\n",
      "w0 = (2, 1), data=\n",
      "[[ 2.]\n",
      " [-1.]]\n",
      "\n",
      "b0 = (), data=\n",
      "3.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#样本数量\n",
    "n = 400\n",
    "\n",
    "# 生成测试用数据集\n",
    "X = tf.random.uniform([n, 2], minval=-10, maxval=10) \n",
    "print(f\"X shape = {X.shape}\")\n",
    "print(f\"X head =\\n{X[:10]}\")\n",
    "print()\n",
    "\n",
    "w0 = tf.constant([[2.0], [-1.0]])\n",
    "print(f\"w0 = {w0.shape}, data=\\n{w0}\")\n",
    "print()\n",
    "\n",
    "b0 = tf.constant(3.0)\n",
    "print(f\"b0 = {b0.shape}, data=\\n{b0}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-12T00:45:48.528691Z",
     "iopub.status.busy": "2020-06-12T00:45:48.528475Z",
     "iopub.status.idle": "2020-06-12T00:45:48.535406Z",
     "shell.execute_reply": "2020-06-12T00:45:48.534399Z",
     "shell.execute_reply.started": "2020-06-12T00:45:48.528662Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal_penalty shape = (400, 1)\n",
      "normal_penalty head =\n",
      "[[ 1.3415803 ]\n",
      " [ 0.39303797]\n",
      " [-0.8475891 ]\n",
      " [ 4.3898935 ]\n",
      " [-0.25815213]\n",
      " [-1.489164  ]\n",
      " [-2.5715966 ]\n",
      " [ 1.164617  ]\n",
      " [ 1.3561958 ]\n",
      " [ 2.670498  ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "normal_penalty = tf.random.normal([n, 1], mean=0.0, stddev=2.0)\n",
    "normal_penalty[:10]\n",
    "print(f\"normal_penalty shape = {normal_penalty.shape}\")\n",
    "print(f\"normal_penalty head =\\n{normal_penalty[:10]}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-12T00:45:48.536636Z",
     "iopub.status.busy": "2020-06-12T00:45:48.536415Z",
     "iopub.status.idle": "2020-06-12T00:45:48.542977Z",
     "shell.execute_reply": "2020-06-12T00:45:48.542077Z",
     "shell.execute_reply.started": "2020-06-12T00:45:48.536607Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y shape = (400, 1)\n",
      "Y head =\n",
      "[[21.261383 ]\n",
      " [ 1.3508093]\n",
      " [-5.2298627]\n",
      " [ 5.1820326]\n",
      " [ 3.101367 ]\n",
      " [-5.3461156]\n",
      " [-8.518938 ]\n",
      " [ 7.03177  ]\n",
      " [ 9.811052 ]\n",
      " [20.541843 ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y = X@w0 + b0 + normal_penalty  # @表示矩阵乘法,增加正态扰动\n",
    "print(f\"Y shape = {Y.shape}\")\n",
    "print(f\"Y head =\\n{Y[:10]}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-12T00:45:48.544170Z",
     "iopub.status.busy": "2020-06-12T00:45:48.543909Z",
     "iopub.status.idle": "2020-06-12T00:45:58.257712Z",
     "shell.execute_reply": "2020-06-12T00:45:58.256805Z",
     "shell.execute_reply.started": "2020-06-12T00:45:48.544122Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========08:45:50==========\n",
      "epoch = 1000  loss = 5.69667673\n",
      "w =\n",
      " [[1.95621347]\n",
      " [-0.864533842]]\n",
      "b =\n",
      " 0.278123409\n",
      "\n",
      "==========08:45:52==========\n",
      "epoch = 2000  loss = 4.74324751\n",
      "w =\n",
      " [[2.0171876]\n",
      " [-0.976967812]]\n",
      "b =\n",
      " 0.532167137\n",
      "\n",
      "==========08:45:54==========\n",
      "epoch = 3000  loss = 4.21288157\n",
      "w =\n",
      " [[2.01716757]\n",
      " [-0.981756806]]\n",
      "b =\n",
      " 0.762274\n",
      "\n",
      "==========08:45:56==========\n",
      "epoch = 4000  loss = 3.77871418\n",
      "w =\n",
      " [[2.0160284]\n",
      " [-0.982959628]]\n",
      "b =\n",
      " 0.970532179\n",
      "\n",
      "==========08:45:58==========\n",
      "epoch = 5000  loss = 3.42311835\n",
      "w =\n",
      " [[2.01500511]\n",
      " [-0.983940899]]\n",
      "b =\n",
      " 1.15900707\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#使用动态图调试\n",
    "\n",
    "w = tf.Variable(tf.random.normal(w0.shape))\n",
    "b = tf.Variable(0.0)\n",
    "\n",
    "def train(epoches):\n",
    "    for epoch in tf.range(1, epoches + 1):\n",
    "        with tf.GradientTape() as tape:\n",
    "            #正向传播求损失\n",
    "            Y_hat = X@w + b\n",
    "            # 损失函数(目标函数)\n",
    "            loss = tf.squeeze(tf.transpose(Y - Y_hat) @ (Y - Y_hat)) / (2.0 * n)   \n",
    "\n",
    "        # 反向传播求梯度\n",
    "        dloss_dw, dloss_db = tape.gradient(loss, [w, b])\n",
    "        # 梯度下降法更新参数\n",
    "        w.assign(w - 0.0001 * dloss_dw)\n",
    "        b.assign(b - 0.0001 * dloss_db)\n",
    "        if epoch % 1000 == 0:\n",
    "            printbar()\n",
    "            tf.print(\"epoch =\", epoch, \" loss =\", loss,)\n",
    "            tf.print(\"w =\\n\", w)\n",
    "            tf.print(\"b =\\n\", b)\n",
    "            tf.print(\"\")\n",
    "\n",
    "train(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-12T00:45:58.259266Z",
     "iopub.status.busy": "2020-06-12T00:45:58.259032Z",
     "iopub.status.idle": "2020-06-12T00:45:59.648250Z",
     "shell.execute_reply": "2020-06-12T00:45:59.646820Z",
     "shell.execute_reply.started": "2020-06-12T00:45:58.259234Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========08:45:58==========\n",
      "epoch = 1000  loss = 2.40704346\n",
      "w = [[2.01104116]\n",
      " [-0.987616]]\n",
      "b = 1.86533523\n",
      "\n",
      "==========08:45:59==========\n",
      "epoch = 2000  loss = 1.89424551\n",
      "w = [[2.00720048]\n",
      " [-0.991193414]]\n",
      "b = 2.55331\n",
      "\n",
      "==========08:45:59==========\n",
      "epoch = 3000  loss = 1.82465148\n",
      "w = [[2.00578475]\n",
      " [-0.992511153]]\n",
      "b = 2.80675554\n",
      "\n",
      "==========08:45:59==========\n",
      "epoch = 4000  loss = 1.81520629\n",
      "w = [[2.00526476]\n",
      " [-0.992996752]]\n",
      "b = 2.90012336\n",
      "\n",
      "==========08:45:59==========\n",
      "epoch = 5000  loss = 1.81392479\n",
      "w = [[2.0050714]\n",
      " [-0.993176222]]\n",
      "b = 2.93451929\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##使用autograph机制转换成静态图加速\n",
    "\n",
    "w = tf.Variable(tf.random.normal(w0.shape))\n",
    "b = tf.Variable(0.0)\n",
    "\n",
    "@tf.function\n",
    "def train(epoches):\n",
    "    for epoch in tf.range(1,epoches+1):\n",
    "        with tf.GradientTape() as tape:\n",
    "            #正向传播求损失\n",
    "            Y_hat = X@w + b\n",
    "            loss = tf.squeeze(tf.transpose(Y-Y_hat)@(Y-Y_hat))/(2.0*n)   \n",
    "\n",
    "        # 反向传播求梯度\n",
    "        dloss_dw,dloss_db = tape.gradient(loss,[w,b])\n",
    "        # 梯度下降法更新参数\n",
    "        w.assign(w - 0.001*dloss_dw)\n",
    "        b.assign(b - 0.001*dloss_db)\n",
    "        if epoch%1000 == 0:\n",
    "            printbar()\n",
    "            tf.print(\"epoch =\",epoch,\" loss =\",loss,)\n",
    "            tf.print(\"w =\",w)\n",
    "            tf.print(\"b =\",b)\n",
    "            tf.print(\"\")\n",
    "train(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 中阶API示例\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**中阶API** 主要包括设置 **各种模型层**、**损失函数**、**优化器**、**数据管道** 和 **特征列** 等等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-12T00:45:59.652849Z",
     "iopub.status.busy": "2020-06-12T00:45:59.652413Z",
     "iopub.status.idle": "2020-06-12T00:45:59.673976Z",
     "shell.execute_reply": "2020-06-12T00:45:59.672688Z",
     "shell.execute_reply.started": "2020-06-12T00:45:59.652791Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w0 shape = (2, 1)\n",
      "w0 =\n",
      "[[ 2.]\n",
      " [-1.]]\n",
      "\n",
      "b0 shape = ()\n",
      "b0 = 3.0\n",
      "\n",
      "X shape = (800, 2)\n",
      "X head =\n",
      "[[ 7.5004997   5.7677536 ]\n",
      " [ 8.66337    -4.95497   ]\n",
      " [-1.4182549  -5.5375457 ]\n",
      " [ 2.0937061  -0.09067059]\n",
      " [ 3.1333466  -6.932769  ]\n",
      " [ 3.7038784  -9.357958  ]\n",
      " [ 7.754307    5.937538  ]\n",
      " [ 1.9160957   6.206255  ]\n",
      " [ 9.265776    0.23511887]\n",
      " [ 5.2307463  -0.39458275]]\n",
      "\n",
      "Y shape = (800, 1)\n",
      "Y head =\n",
      "[[12.70994  ]\n",
      " [23.17971  ]\n",
      " [ 3.7820983]\n",
      " [ 9.02637  ]\n",
      " [16.671679 ]\n",
      " [21.872562 ]\n",
      " [11.417866 ]\n",
      " [ 1.8504803]\n",
      " [19.674597 ]\n",
      " [12.413099 ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#样本数量\n",
    "n = 800\n",
    "\n",
    "# 生成测试用数据集\n",
    "X = tf.random.uniform([n, 2], minval=-10, maxval=10) \n",
    "\n",
    "w0 = tf.constant([[2.0], [-1.0]])\n",
    "b0 = tf.constant(3.0)\n",
    "\n",
    "Y = X @ w0 + b0 + tf.random.normal([n, 1], mean=0.0, stddev=2.0)  # @表示矩阵乘法,增加正态扰动\n",
    "\n",
    "print(f\"w0 shape = {w0.shape}\")\n",
    "print(f\"w0 =\\n{w0}\")\n",
    "print()\n",
    "print(f\"b0 shape = {b0.shape}\")\n",
    "print(f\"b0 = {b0}\")\n",
    "print()\n",
    "print(f\"X shape = {X.shape}\")\n",
    "print(f\"X head =\\n{X[:10]}\")\n",
    "print()\n",
    "print(f\"Y shape = {Y.shape}\")\n",
    "print(f\"Y head =\\n{Y[:10]}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-12T00:45:59.676126Z",
     "iopub.status.busy": "2020-06-12T00:45:59.675781Z",
     "iopub.status.idle": "2020-06-12T00:45:59.689286Z",
     "shell.execute_reply": "2020-06-12T00:45:59.688074Z",
     "shell.execute_reply.started": "2020-06-12T00:45:59.676079Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None, 2), (None, 1)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#构建输入数据管道\n",
    "ds = tf.data.Dataset.from_tensor_slices((X, Y)) \\\n",
    "     .shuffle(buffer_size = 1000).batch(100) \\\n",
    "     .prefetch(tf.data.experimental.AUTOTUNE)  \n",
    "\n",
    "#定义优化器\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.001)\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-12T00:45:59.691155Z",
     "iopub.status.busy": "2020-06-12T00:45:59.690823Z",
     "iopub.status.idle": "2020-06-12T00:46:22.018560Z",
     "shell.execute_reply": "2020-06-12T00:46:22.016918Z",
     "shell.execute_reply.started": "2020-06-12T00:45:59.691109Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========08:46:04==========\n",
      "epoch = 100 , loss = 5.61641741\n",
      "w =\n",
      " [[2.02299]\n",
      " [-0.991715]]\n",
      "b = [2.44163775]\n",
      "\n",
      "==========08:46:08==========\n",
      "epoch = 200 , loss = 4.1973815\n",
      "w =\n",
      " [[2.01992178]\n",
      " [-0.989192605]]\n",
      "b = [2.9430294]\n",
      "\n",
      "==========08:46:13==========\n",
      "epoch = 300 , loss = 3.57325673\n",
      "w =\n",
      " [[2.02173185]\n",
      " [-0.987432599]]\n",
      "b = [3.04419]\n",
      "\n",
      "==========08:46:17==========\n",
      "epoch = 400 , loss = 3.83709264\n",
      "w =\n",
      " [[2.02009773]\n",
      " [-0.988284588]]\n",
      "b = [3.06463099]\n",
      "\n",
      "==========08:46:21==========\n",
      "epoch = 500 , loss = 3.72241354\n",
      "w =\n",
      " [[2.02127457]\n",
      " [-0.988627136]]\n",
      "b = [3.06869936]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "linear = keras.layers.Dense(units = 1)\n",
    "linear.build(input_shape = (2, )) \n",
    "\n",
    "@tf.function\n",
    "def train(epoches):\n",
    "    for epoch in tf.range(1, epoches + 1):\n",
    "        L = tf.constant(0.0) #使用L记录loss值\n",
    "        for X_batch, Y_batch in ds:\n",
    "            with tf.GradientTape() as tape:\n",
    "                Y_hat = linear(X_batch)\n",
    "                loss = keras.losses.mean_squared_error(tf.reshape(Y_hat, [-1]), tf.reshape(Y_batch, [-1]))\n",
    "            grads = tape.gradient(loss, linear.variables)\n",
    "            optimizer.apply_gradients(zip(grads, linear.variables))\n",
    "            L = loss\n",
    "\n",
    "        if(epoch % 100 == 0):\n",
    "            printbar()\n",
    "            tf.print(\"epoch =\", epoch, \", loss =\", L)\n",
    "            tf.print(\"w =\\n\", linear.kernel)\n",
    "            tf.print(\"b =\", linear.bias)\n",
    "            tf.print(\"\")\n",
    "\n",
    "train(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 高阶API示例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**高阶API** 主要为 *tf.keras.models* 提供的模型类接口。\n",
    "\n",
    "使用Keras接口有以下3种方式构建模型：\n",
    "1. 使用Sequential按层顺序构建模型；\n",
    "2. 使用函数式API构建任意结构模型；\n",
    "3. 继承Model基类构建自定义模型；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keras.models.Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-12T00:49:42.467903Z",
     "iopub.status.busy": "2020-06-12T00:49:42.467353Z",
     "iopub.status.idle": "2020-06-12T00:49:42.492506Z",
     "shell.execute_reply": "2020-06-12T00:49:42.491091Z",
     "shell.execute_reply.started": "2020-06-12T00:49:42.467839Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w0 shape = (2, 1)\n",
      "w0 =\n",
      "[[ 2.]\n",
      " [-1.]]\n",
      "\n",
      "b0 shape = ()\n",
      "b0 = 3.0\n",
      "\n",
      "X shape = (800, 2)\n",
      "X head =\n",
      "[[ 2.298603   -3.0598927 ]\n",
      " [-5.310471   -9.0469    ]\n",
      " [-5.8309317  -2.052095  ]\n",
      " [-6.204927    3.9892693 ]\n",
      " [-7.5203967   7.8968925 ]\n",
      " [-0.44991684  0.7949209 ]\n",
      " [ 8.628441    3.607974  ]\n",
      " [ 3.73672     8.150255  ]\n",
      " [-1.7515545  -6.5004706 ]\n",
      " [ 7.695341    5.374346  ]]\n",
      "\n",
      "Y shape = (800, 1)\n",
      "Y head =\n",
      "[[ 12.469965 ]\n",
      " [  0.1427896]\n",
      " [ -6.081075 ]\n",
      " [-15.3535595]\n",
      " [-22.368181 ]\n",
      " [  0.81478  ]\n",
      " [ 15.236221 ]\n",
      " [  5.1185064]\n",
      " [  4.0363536]\n",
      " [ 15.379247 ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#样本数量\n",
    "n = 800\n",
    "\n",
    "# 生成测试用数据集\n",
    "X = tf.random.uniform([n, 2], minval=-10, maxval=10) \n",
    "w0 = tf.constant([[2.0], [-1.0]])\n",
    "b0 = tf.constant(3.0)\n",
    "\n",
    "Y = X@w0 + b0 + tf.random.normal([n, 1], mean=0.0, stddev=2.0)  # @表示矩阵乘法,增加正态扰动\n",
    "\n",
    "print(f\"w0 shape = {w0.shape}\")\n",
    "print(f\"w0 =\\n{w0}\")\n",
    "print()\n",
    "print(f\"b0 shape = {b0.shape}\")\n",
    "print(f\"b0 = {b0}\")\n",
    "print()\n",
    "print(f\"X shape = {X.shape}\")\n",
    "print(f\"X head =\\n{X[:10]}\")\n",
    "print()\n",
    "print(f\"Y shape = {Y.shape}\")\n",
    "print(f\"Y head =\\n{Y[:10]}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-12T00:49:42.970080Z",
     "iopub.status.busy": "2020-06-12T00:49:42.969642Z",
     "iopub.status.idle": "2020-06-12T00:49:43.009434Z",
     "shell.execute_reply": "2020-06-12T00:49:43.008293Z",
     "shell.execute_reply.started": "2020-06-12T00:49:42.970021Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 3\n",
      "Trainable params: 3\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "linear = keras.models.Sequential()\n",
    "linear.add(keras.layers.Dense(1, input_shape =(2, )))\n",
    "linear.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-12T00:50:49.607666Z",
     "iopub.status.busy": "2020-06-12T00:50:49.607089Z",
     "iopub.status.idle": "2020-06-12T00:51:04.242544Z",
     "shell.execute_reply": "2020-06-12T00:51:04.241059Z",
     "shell.execute_reply.started": "2020-06-12T00:50:49.607601Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples\n",
      "Epoch 1/200\n",
      "800/800 [==============================] - 0s 356us/sample - loss: 3.5310 - mae: 1.5204\n",
      "Epoch 2/200\n",
      "800/800 [==============================] - 0s 72us/sample - loss: 3.5285 - mae: 1.5195\n",
      "Epoch 3/200\n",
      "800/800 [==============================] - 0s 74us/sample - loss: 3.5306 - mae: 1.5203\n",
      "Epoch 4/200\n",
      "800/800 [==============================] - 0s 79us/sample - loss: 3.5301 - mae: 1.5202\n",
      "Epoch 5/200\n",
      "800/800 [==============================] - 0s 82us/sample - loss: 3.5286 - mae: 1.5199\n",
      "Epoch 6/200\n",
      "800/800 [==============================] - 0s 81us/sample - loss: 3.5303 - mae: 1.5201\n",
      "Epoch 7/200\n",
      "800/800 [==============================] - 0s 75us/sample - loss: 3.5303 - mae: 1.5202\n",
      "Epoch 8/200\n",
      "800/800 [==============================] - 0s 88us/sample - loss: 3.5292 - mae: 1.5202\n",
      "Epoch 9/200\n",
      "800/800 [==============================] - 0s 76us/sample - loss: 3.5303 - mae: 1.5206\n",
      "Epoch 10/200\n",
      "800/800 [==============================] - 0s 72us/sample - loss: 3.5297 - mae: 1.5201\n",
      "Epoch 11/200\n",
      "800/800 [==============================] - 0s 76us/sample - loss: 3.5290 - mae: 1.5203\n",
      "Epoch 12/200\n",
      "800/800 [==============================] - 0s 78us/sample - loss: 3.5276 - mae: 1.5199\n",
      "Epoch 13/200\n",
      "800/800 [==============================] - 0s 80us/sample - loss: 3.5283 - mae: 1.5200\n",
      "Epoch 14/200\n",
      "800/800 [==============================] - 0s 83us/sample - loss: 3.5288 - mae: 1.5197\n",
      "Epoch 15/200\n",
      "800/800 [==============================] - 0s 87us/sample - loss: 3.5300 - mae: 1.5200\n",
      "Epoch 16/200\n",
      "800/800 [==============================] - 0s 86us/sample - loss: 3.5278 - mae: 1.5198\n",
      "Epoch 17/200\n",
      "800/800 [==============================] - 0s 84us/sample - loss: 3.5291 - mae: 1.5200\n",
      "Epoch 18/200\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 3.5290 - mae: 1.5197\n",
      "Epoch 19/200\n",
      "800/800 [==============================] - 0s 88us/sample - loss: 3.5273 - mae: 1.5195\n",
      "Epoch 20/200\n",
      "800/800 [==============================] - 0s 86us/sample - loss: 3.5286 - mae: 1.5197\n",
      "Epoch 21/200\n",
      "800/800 [==============================] - 0s 82us/sample - loss: 3.5279 - mae: 1.5195\n",
      "Epoch 22/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 3.5272 - mae: 1.5195\n",
      "Epoch 23/200\n",
      "800/800 [==============================] - 0s 88us/sample - loss: 3.5297 - mae: 1.5202\n",
      "Epoch 24/200\n",
      "800/800 [==============================] - 0s 88us/sample - loss: 3.5282 - mae: 1.5197\n",
      "Epoch 25/200\n",
      "800/800 [==============================] - 0s 85us/sample - loss: 3.5309 - mae: 1.5206\n",
      "Epoch 26/200\n",
      "800/800 [==============================] - 0s 88us/sample - loss: 3.5297 - mae: 1.5199\n",
      "Epoch 27/200\n",
      "800/800 [==============================] - 0s 87us/sample - loss: 3.5322 - mae: 1.5205\n",
      "Epoch 28/200\n",
      "800/800 [==============================] - 0s 85us/sample - loss: 3.5319 - mae: 1.5207\n",
      "Epoch 29/200\n",
      "800/800 [==============================] - 0s 86us/sample - loss: 3.5282 - mae: 1.5199\n",
      "Epoch 30/200\n",
      "800/800 [==============================] - 0s 83us/sample - loss: 3.5287 - mae: 1.5199\n",
      "Epoch 31/200\n",
      "800/800 [==============================] - 0s 83us/sample - loss: 3.5285 - mae: 1.5197\n",
      "Epoch 32/200\n",
      "800/800 [==============================] - 0s 82us/sample - loss: 3.5329 - mae: 1.5205\n",
      "Epoch 33/200\n",
      "800/800 [==============================] - 0s 86us/sample - loss: 3.5309 - mae: 1.5202\n",
      "Epoch 34/200\n",
      "800/800 [==============================] - 0s 86us/sample - loss: 3.5283 - mae: 1.5200\n",
      "Epoch 35/200\n",
      "800/800 [==============================] - 0s 83us/sample - loss: 3.5301 - mae: 1.5201\n",
      "Epoch 36/200\n",
      "800/800 [==============================] - 0s 79us/sample - loss: 3.5304 - mae: 1.5196\n",
      "Epoch 37/200\n",
      "800/800 [==============================] - 0s 79us/sample - loss: 3.5285 - mae: 1.5198\n",
      "Epoch 38/200\n",
      "800/800 [==============================] - 0s 81us/sample - loss: 3.5298 - mae: 1.5204\n",
      "Epoch 39/200\n",
      "800/800 [==============================] - 0s 81us/sample - loss: 3.5285 - mae: 1.5201\n",
      "Epoch 40/200\n",
      "800/800 [==============================] - 0s 84us/sample - loss: 3.5287 - mae: 1.5195\n",
      "Epoch 41/200\n",
      "800/800 [==============================] - 0s 79us/sample - loss: 3.5289 - mae: 1.5196\n",
      "Epoch 42/200\n",
      "800/800 [==============================] - 0s 77us/sample - loss: 3.5290 - mae: 1.5202\n",
      "Epoch 43/200\n",
      "800/800 [==============================] - 0s 73us/sample - loss: 3.5314 - mae: 1.5207\n",
      "Epoch 44/200\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 3.5280 - mae: 1.5200\n",
      "Epoch 45/200\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 3.5320 - mae: 1.5206\n",
      "Epoch 46/200\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 3.5278 - mae: 1.5204\n",
      "Epoch 47/200\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 3.5292 - mae: 1.5200\n",
      "Epoch 48/200\n",
      "800/800 [==============================] - 0s 73us/sample - loss: 3.5301 - mae: 1.5208\n",
      "Epoch 49/200\n",
      "800/800 [==============================] - 0s 72us/sample - loss: 3.5308 - mae: 1.5203\n",
      "Epoch 50/200\n",
      "800/800 [==============================] - 0s 72us/sample - loss: 3.5285 - mae: 1.5200\n",
      "Epoch 51/200\n",
      "800/800 [==============================] - 0s 74us/sample - loss: 3.5327 - mae: 1.5206\n",
      "Epoch 52/200\n",
      "800/800 [==============================] - 0s 74us/sample - loss: 3.5284 - mae: 1.5198\n",
      "Epoch 53/200\n",
      "800/800 [==============================] - 0s 79us/sample - loss: 3.5285 - mae: 1.5197\n",
      "Epoch 54/200\n",
      "800/800 [==============================] - 0s 81us/sample - loss: 3.5286 - mae: 1.5196\n",
      "Epoch 55/200\n",
      "800/800 [==============================] - 0s 78us/sample - loss: 3.5316 - mae: 1.5206\n",
      "Epoch 56/200\n",
      "800/800 [==============================] - 0s 88us/sample - loss: 3.5278 - mae: 1.5196\n",
      "Epoch 57/200\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 3.5288 - mae: 1.5200\n",
      "Epoch 58/200\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 3.5309 - mae: 1.5207\n",
      "Epoch 59/200\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 3.5305 - mae: 1.5203\n",
      "Epoch 60/200\n",
      "800/800 [==============================] - 0s 87us/sample - loss: 3.5279 - mae: 1.5199\n",
      "Epoch 61/200\n",
      "800/800 [==============================] - 0s 88us/sample - loss: 3.5311 - mae: 1.5202\n",
      "Epoch 62/200\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 3.5295 - mae: 1.5198\n",
      "Epoch 63/200\n",
      "800/800 [==============================] - 0s 87us/sample - loss: 3.5277 - mae: 1.5194\n",
      "Epoch 64/200\n",
      "800/800 [==============================] - 0s 86us/sample - loss: 3.5334 - mae: 1.5204\n",
      "Epoch 65/200\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 3.5308 - mae: 1.5200\n",
      "Epoch 66/200\n",
      "800/800 [==============================] - 0s 87us/sample - loss: 3.5295 - mae: 1.5200\n",
      "Epoch 67/200\n",
      "800/800 [==============================] - 0s 85us/sample - loss: 3.5295 - mae: 1.5202\n",
      "Epoch 68/200\n",
      "800/800 [==============================] - 0s 84us/sample - loss: 3.5330 - mae: 1.5205\n",
      "Epoch 69/200\n",
      "800/800 [==============================] - 0s 88us/sample - loss: 3.5290 - mae: 1.5203\n",
      "Epoch 70/200\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 3.5306 - mae: 1.5199\n",
      "Epoch 71/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 3.5289 - mae: 1.5200\n",
      "Epoch 72/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 3.5292 - mae: 1.5199\n",
      "Epoch 73/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 3.5304 - mae: 1.5209\n",
      "Epoch 74/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 3.5331 - mae: 1.5210\n",
      "Epoch 75/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 3.5285 - mae: 1.5201\n",
      "Epoch 76/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 3.5290 - mae: 1.5198\n",
      "Epoch 77/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 3.5284 - mae: 1.5198\n",
      "Epoch 78/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 3.5286 - mae: 1.5201\n",
      "Epoch 79/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 3.5287 - mae: 1.5195\n",
      "Epoch 80/200\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 3.5310 - mae: 1.5202\n",
      "Epoch 81/200\n",
      "800/800 [==============================] - 0s 101us/sample - loss: 3.5288 - mae: 1.5199\n",
      "Epoch 82/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 3.5280 - mae: 1.5198\n",
      "Epoch 83/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 3.5293 - mae: 1.5200\n",
      "Epoch 84/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 3.5290 - mae: 1.5198\n",
      "Epoch 85/200\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 3.5293 - mae: 1.5198\n",
      "Epoch 86/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 3.5280 - mae: 1.5196\n",
      "Epoch 87/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 3.5276 - mae: 1.5197\n",
      "Epoch 88/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 3.5295 - mae: 1.5200\n",
      "Epoch 89/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 3.5282 - mae: 1.5198\n",
      "Epoch 90/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 3.5333 - mae: 1.5204\n",
      "Epoch 91/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 3.5332 - mae: 1.5204\n",
      "Epoch 92/200\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 3.5278 - mae: 1.5199\n",
      "Epoch 93/200\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 3.5293 - mae: 1.5198\n",
      "Epoch 94/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 3.5290 - mae: 1.5200\n",
      "Epoch 95/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 3.5296 - mae: 1.5200\n",
      "Epoch 96/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 3.5307 - mae: 1.5206\n",
      "Epoch 97/200\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 3.5283 - mae: 1.5201\n",
      "Epoch 98/200\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 3.5300 - mae: 1.5200\n",
      "Epoch 99/200\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 3.5288 - mae: 1.5192\n",
      "Epoch 100/200\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 3.5301 - mae: 1.5204\n",
      "Epoch 101/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 3.5291 - mae: 1.5196\n",
      "Epoch 102/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 3.5294 - mae: 1.5203\n",
      "Epoch 103/200\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 3.5276 - mae: 1.5197\n",
      "Epoch 104/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 3.5288 - mae: 1.5201\n",
      "Epoch 105/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 3.5277 - mae: 1.5197\n",
      "Epoch 106/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 3.5289 - mae: 1.5200\n",
      "Epoch 107/200\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 3.5277 - mae: 1.5198\n",
      "Epoch 108/200\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 3.5282 - mae: 1.5199\n",
      "Epoch 109/200\n",
      "800/800 [==============================] - 0s 88us/sample - loss: 3.5304 - mae: 1.5202\n",
      "Epoch 110/200\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 3.5281 - mae: 1.5197\n",
      "Epoch 111/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 3.5305 - mae: 1.5202\n",
      "Epoch 112/200\n",
      "800/800 [==============================] - 0s 88us/sample - loss: 3.5279 - mae: 1.5198\n",
      "Epoch 113/200\n",
      "800/800 [==============================] - 0s 88us/sample - loss: 3.5280 - mae: 1.5199\n",
      "Epoch 114/200\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 3.5280 - mae: 1.5198\n",
      "Epoch 115/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 3.5283 - mae: 1.5199\n",
      "Epoch 116/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 3.5310 - mae: 1.5201\n",
      "Epoch 117/200\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 3.5308 - mae: 1.5205\n",
      "Epoch 118/200\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 3.5292 - mae: 1.5197\n",
      "Epoch 119/200\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 3.5289 - mae: 1.5201\n",
      "Epoch 120/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 3.5305 - mae: 1.5204\n",
      "Epoch 121/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 3.5294 - mae: 1.5199\n",
      "Epoch 122/200\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 3.5293 - mae: 1.5201\n",
      "Epoch 123/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 3.5272 - mae: 1.5198\n",
      "Epoch 124/200\n",
      "800/800 [==============================] - 0s 80us/sample - loss: 3.5294 - mae: 1.5203\n",
      "Epoch 125/200\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 3.5304 - mae: 1.5202\n",
      "Epoch 126/200\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 3.5297 - mae: 1.5201\n",
      "Epoch 127/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 3.5316 - mae: 1.5199\n",
      "Epoch 128/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 3.5305 - mae: 1.5198\n",
      "Epoch 129/200\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 3.5286 - mae: 1.5200\n",
      "Epoch 130/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 3.5280 - mae: 1.5199\n",
      "Epoch 131/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 3.5293 - mae: 1.5200\n",
      "Epoch 132/200\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 3.5304 - mae: 1.5202\n",
      "Epoch 133/200\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 3.5288 - mae: 1.5198\n",
      "Epoch 134/200\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 3.5301 - mae: 1.5199\n",
      "Epoch 135/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 3.5290 - mae: 1.5199\n",
      "Epoch 136/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 3.5288 - mae: 1.5197\n",
      "Epoch 137/200\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 3.5280 - mae: 1.5199\n",
      "Epoch 138/200\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 3.5305 - mae: 1.5208\n",
      "Epoch 139/200\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 3.5272 - mae: 1.5198\n",
      "Epoch 140/200\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 3.5284 - mae: 1.5200\n",
      "Epoch 141/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 3.5288 - mae: 1.5199\n",
      "Epoch 142/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 3.5285 - mae: 1.5200\n",
      "Epoch 143/200\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 3.5327 - mae: 1.5203\n",
      "Epoch 144/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 3.5269 - mae: 1.5197\n",
      "Epoch 145/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 3.5300 - mae: 1.5202\n",
      "Epoch 146/200\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 3.5284 - mae: 1.5199\n",
      "Epoch 147/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 3.5292 - mae: 1.5203\n",
      "Epoch 148/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 3.5306 - mae: 1.5201\n",
      "Epoch 149/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 3.5279 - mae: 1.5196\n",
      "Epoch 150/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 3.5310 - mae: 1.5204\n",
      "Epoch 151/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 3.5313 - mae: 1.5208\n",
      "Epoch 152/200\n",
      "800/800 [==============================] - 0s 88us/sample - loss: 3.5287 - mae: 1.5196\n",
      "Epoch 153/200\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 3.5276 - mae: 1.5197\n",
      "Epoch 154/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 3.5282 - mae: 1.5196\n",
      "Epoch 155/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 3.5295 - mae: 1.5200\n",
      "Epoch 156/200\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 3.5301 - mae: 1.5205\n",
      "Epoch 157/200\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 3.5280 - mae: 1.5197\n",
      "Epoch 158/200\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 3.5314 - mae: 1.5206\n",
      "Epoch 159/200\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 3.5323 - mae: 1.5211\n",
      "Epoch 160/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 3.5299 - mae: 1.5201\n",
      "Epoch 161/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 3.5312 - mae: 1.5209\n",
      "Epoch 162/200\n",
      "800/800 [==============================] - 0s 88us/sample - loss: 3.5291 - mae: 1.5201\n",
      "Epoch 163/200\n",
      "800/800 [==============================] - 0s 88us/sample - loss: 3.5294 - mae: 1.5200\n",
      "Epoch 164/200\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 3.5279 - mae: 1.5197\n",
      "Epoch 165/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 3.5279 - mae: 1.5199\n",
      "Epoch 166/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 3.5292 - mae: 1.5203\n",
      "Epoch 167/200\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 3.5285 - mae: 1.5197\n",
      "Epoch 168/200\n",
      "800/800 [==============================] - 0s 87us/sample - loss: 3.5277 - mae: 1.5197\n",
      "Epoch 169/200\n",
      "800/800 [==============================] - 0s 87us/sample - loss: 3.5276 - mae: 1.5198\n",
      "Epoch 170/200\n",
      "800/800 [==============================] - 0s 85us/sample - loss: 3.5293 - mae: 1.5196\n",
      "Epoch 171/200\n",
      "800/800 [==============================] - 0s 87us/sample - loss: 3.5296 - mae: 1.5204\n",
      "Epoch 172/200\n",
      "800/800 [==============================] - 0s 88us/sample - loss: 3.5290 - mae: 1.5196\n",
      "Epoch 173/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 3.5291 - mae: 1.5201\n",
      "Epoch 174/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 3.5297 - mae: 1.5202\n",
      "Epoch 175/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 3.5312 - mae: 1.5206\n",
      "Epoch 176/200\n",
      "800/800 [==============================] - 0s 84us/sample - loss: 3.5301 - mae: 1.5203\n",
      "Epoch 177/200\n",
      "800/800 [==============================] - 0s 84us/sample - loss: 3.5275 - mae: 1.5197\n",
      "Epoch 178/200\n",
      "800/800 [==============================] - 0s 88us/sample - loss: 3.5292 - mae: 1.5194\n",
      "Epoch 179/200\n",
      "800/800 [==============================] - 0s 87us/sample - loss: 3.5279 - mae: 1.5196\n",
      "Epoch 180/200\n",
      "800/800 [==============================] - 0s 86us/sample - loss: 3.5283 - mae: 1.5197\n",
      "Epoch 181/200\n",
      "800/800 [==============================] - 0s 88us/sample - loss: 3.5278 - mae: 1.5198\n",
      "Epoch 182/200\n",
      "800/800 [==============================] - 0s 87us/sample - loss: 3.5283 - mae: 1.5200\n",
      "Epoch 183/200\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 3.5274 - mae: 1.5196\n",
      "Epoch 184/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 3.5297 - mae: 1.5204\n",
      "Epoch 185/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 3.5316 - mae: 1.5211\n",
      "Epoch 186/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 3.5285 - mae: 1.5196\n",
      "Epoch 187/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 3.5306 - mae: 1.5205\n",
      "Epoch 188/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 3.5314 - mae: 1.5206\n",
      "Epoch 189/200\n",
      "800/800 [==============================] - 0s 97us/sample - loss: 3.5319 - mae: 1.5205\n",
      "Epoch 190/200\n",
      "800/800 [==============================] - 0s 96us/sample - loss: 3.5283 - mae: 1.5196\n",
      "Epoch 191/200\n",
      "800/800 [==============================] - 0s 98us/sample - loss: 3.5279 - mae: 1.5198\n",
      "Epoch 192/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 3.5288 - mae: 1.5197\n",
      "Epoch 193/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 3.5286 - mae: 1.5197\n",
      "Epoch 194/200\n",
      "800/800 [==============================] - 0s 97us/sample - loss: 3.5292 - mae: 1.5200\n",
      "Epoch 195/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 3.5287 - mae: 1.5198\n",
      "Epoch 196/200\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 3.5300 - mae: 1.5205\n",
      "Epoch 197/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 3.5293 - mae: 1.5199\n",
      "Epoch 198/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 3.5299 - mae: 1.5202\n",
      "Epoch 199/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 3.5304 - mae: 1.5203\n",
      "Epoch 200/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 3.5283 - mae: 1.5197\n",
      "w =\n",
      " [[1.99109519]\n",
      " [-0.998652577]]\n",
      "b =  [2.98188734]\n"
     ]
    }
   ],
   "source": [
    "### 使用fit方法进行训练\n",
    "\n",
    "linear.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "linear.fit(X, Y, batch_size = 20, epochs = 200)  \n",
    "\n",
    "tf.print(\"w =\\n\", linear.layers[0].kernel)\n",
    "tf.print(\"b = \", linear.layers[0].bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 继承 Model基类 构建自定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-12T00:52:30.668566Z",
     "iopub.status.busy": "2020-06-12T00:52:30.668006Z",
     "iopub.status.idle": "2020-06-12T00:52:30.698451Z",
     "shell.execute_reply": "2020-06-12T00:52:30.697118Z",
     "shell.execute_reply.started": "2020-06-12T00:52:30.668503Z"
    }
   },
   "outputs": [],
   "source": [
    "#样本数量\n",
    "n = 800\n",
    "\n",
    "# 生成测试用数据集\n",
    "X = tf.random.uniform([n, 2], minval=-10, maxval=10) \n",
    "w0 = tf.constant([[2.0], [-1.0]])\n",
    "b0 = tf.constant(3.0)\n",
    "\n",
    "Y = X@w0 + b0 + tf.random.normal([n, 1], mean=0.0, stddev=2.0)  # @表示矩阵乘法,增加正态扰动\n",
    "\n",
    "ds_train = tf.data.Dataset.from_tensor_slices((X[0:n*3//4,:],Y[0:n*3//4,:])) \\\n",
    "     .shuffle(buffer_size = 1000).batch(20) \\\n",
    "     .prefetch(tf.data.experimental.AUTOTUNE) \\\n",
    "     .cache()\n",
    "\n",
    "ds_valid = tf.data.Dataset.from_tensor_slices((X[n*3//4:,:],Y[n*3//4:,:])) \\\n",
    "     .shuffle(buffer_size = 1000).batch(20) \\\n",
    "     .prefetch(tf.data.experimental.AUTOTUNE) \\\n",
    "     .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-12T00:53:04.078549Z",
     "iopub.status.busy": "2020-06-12T00:53:04.077985Z",
     "iopub.status.idle": "2020-06-12T00:53:04.118687Z",
     "shell.execute_reply": "2020-06-12T00:53:04.117463Z",
     "shell.execute_reply.started": "2020-06-12T00:53:04.078485Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  3         \n",
      "=================================================================\n",
      "Total params: 3\n",
      "Trainable params: 3\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "class MyModel(keras.models.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.dense1 = keras.layers.Dense(1)   \n",
    "        super(MyModel,self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        y = self.dense1(x)\n",
    "        return(y)\n",
    "\n",
    "model = MyModel()\n",
    "model.build(input_shape =(None,2))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-12T00:58:33.031571Z",
     "iopub.status.busy": "2020-06-12T00:58:33.031020Z",
     "iopub.status.idle": "2020-06-12T00:59:15.956428Z",
     "shell.execute_reply": "2020-06-12T00:59:15.954663Z",
     "shell.execute_reply.started": "2020-06-12T00:58:33.031509Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========08:58:44==========\n",
      "Epoch=100, Loss:3.58331847, MAE:1.5213474, Valid Loss:4.64950371, Valid MAE:1.69223499\n",
      "w=\n",
      " [[1.99570811]\n",
      " [-0.992921174]]\n",
      "b= [2.98471689]\n",
      "\n",
      "==========08:58:55==========\n",
      "Epoch=200, Loss:3.58328462, MAE:1.52133608, Valid Loss:4.64958668, Valid MAE:1.69224811\n",
      "w=\n",
      " [[1.99570811]\n",
      " [-0.992920637]]\n",
      "b= [2.98473048]\n",
      "\n",
      "==========08:59:05==========\n",
      "Epoch=300, Loss:3.58325744, MAE:1.52133095, Valid Loss:4.64962721, Valid MAE:1.69222784\n",
      "w=\n",
      " [[1.99570811]\n",
      " [-0.992920578]]\n",
      "b= [2.98473048]\n",
      "\n",
      "==========08:59:15==========\n",
      "Epoch=400, Loss:3.58330536, MAE:1.5213629, Valid Loss:4.64963579, Valid MAE:1.69222236\n",
      "w=\n",
      " [[1.99570811]\n",
      " [-0.992920578]]\n",
      "b= [2.98473048]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### 自定义训练循环(专家教程)\n",
    "\n",
    "optimizer = keras.optimizers.Adam()\n",
    "loss_func = keras.losses.MeanSquaredError()\n",
    "\n",
    "train_loss = keras.metrics.Mean(name='train_loss')\n",
    "train_metric = keras.metrics.MeanAbsoluteError(name='train_mae')\n",
    "\n",
    "valid_loss = keras.metrics.Mean(name='valid_loss')\n",
    "valid_metric = keras.metrics.MeanAbsoluteError(name='valid_mae')\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(model, features, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(features)\n",
    "        loss = loss_func(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss.update_state(loss)\n",
    "    train_metric.update_state(labels, predictions)\n",
    "\n",
    "@tf.function\n",
    "def valid_step(model, features, labels):\n",
    "    predictions = model(features)\n",
    "    batch_loss = loss_func(labels, predictions)\n",
    "    valid_loss.update_state(batch_loss)\n",
    "    valid_metric.update_state(labels, predictions)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_model(model, ds_train, ds_valid, epochs):\n",
    "    for epoch in tf.range(1, epochs + 1):\n",
    "        for features, labels in ds_train:\n",
    "            train_step(model, features, labels)\n",
    "\n",
    "        for features, labels in ds_valid:\n",
    "            valid_step(model, features, labels)\n",
    "\n",
    "        logs = 'Epoch={}, Loss:{}, MAE:{}, Valid Loss:{}, Valid MAE:{}'\n",
    "\n",
    "        if  epoch % 100 ==0:\n",
    "            printbar()\n",
    "            tf.print(tf.strings.format(logs,\n",
    "            (epoch, train_loss.result(), train_metric.result(), valid_loss.result(), valid_metric.result())))\n",
    "            tf.print(\"w=\\n\", model.layers[0].kernel)\n",
    "            tf.print(\"b=\", model.layers[0].bias)\n",
    "            tf.print(\"\")\n",
    "\n",
    "        train_loss.reset_states()\n",
    "        valid_loss.reset_states()\n",
    "        train_metric.reset_states()\n",
    "        valid_metric.reset_states()\n",
    "\n",
    "train_model(model, ds_train, ds_valid, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
