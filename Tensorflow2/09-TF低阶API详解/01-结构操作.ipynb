{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 张量(Tensor)的结构操作"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "tf.__version__"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**张量结构操作** 如下：\n",
    "- 张量创建；\n",
    "- 索引切片；\n",
    "- 维度变换；\n",
    "- 合并分割；\n",
    "- ..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 创建张量"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 创建 常量\n",
    "a = tf.constant([1, 2, 3], dtype=tf.float32)\n",
    "\n",
    "# 创建 变量\n",
    "x = tf.Variable(1.0, name=\"x\", dtype=tf.float32)\n",
    "\n",
    "tf.print(f\"a shape = {a.shape}\")\n",
    "tf.print(f\"a = {a}\")\n",
    "print()\n",
    "tf.print(f\"x shape = {x.shape}\")\n",
    "tf.print(f\"x = {x}\")\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 创建 Vector(一维张量)\n",
    "\n",
    "# 1.\n",
    "vec_a = tf.range(1, 10, delta=2)\n",
    "\n",
    "# 2.\n",
    "vec_b = tf.linspace(0.0, 2 * 3.14, 10)\n",
    "\n",
    "print(f\"vec_a shape = {vec_a.shape}\")\n",
    "print(f\"vec_a =\\n{vec_a}\")\n",
    "print()\n",
    "print(f\"vec_b shape = {vec_b.shape}\")\n",
    "print(f\"vec_b =\\n{vec_b}\")\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 创建 Matrix(二维张量)\n",
    "\n",
    "# 1.\n",
    "m_ones = tf.ones([2, 2])\n",
    "\n",
    "m_zeros = tf.zeros([3, 3])\n",
    "\n",
    "m_zeros_1 = tf.zeros_like(m_ones, dtype=tf.float32)\n",
    "\n",
    "m_zeros_2 = tf.fill((3, 2), 5)\n",
    "\n",
    "\n",
    "print(f\"【m_ones】 shape = {m_ones.shape}\")\n",
    "print(f\"【m_ones】 =\\n{m_ones}\")\n",
    "print()\n",
    "print(f\"【m_zeros】 shape = {m_zeros.shape}\")\n",
    "print(f\"【m_zeros】 =\\n{m_zeros}\")\n",
    "print()\n",
    "print(f\"【m_zeros_1】 shape = {m_zeros_1.shape}\")\n",
    "print(f\"【m_zeros_1】 =\\n{m_zeros_1}\")\n",
    "print()\n",
    "print(f\"【m_zeros_2】 shape = {m_zeros_2.shape}\")\n",
    "print(f\"【m_zeros_2】 =\\n{m_zeros_2}\")\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 特殊矩阵\n",
    "# 单位矩阵\n",
    "m_eye = tf.eye(3, 3)\n",
    "\n",
    "# 对角阵\n",
    "m_diag = tf.linalg.diag([1, 2, 3])\n",
    "\n",
    "print(f\"【m_eye】 shape = {m_eye.shape}\")\n",
    "print(f\"【m_eye】 =\\n{m_eye}\")\n",
    "print()\n",
    "print(f\"【m_diag】 shape = {m_diag.shape}\")\n",
    "print(f\"【m_diag】 =\\n{m_diag}\")\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 初始化 随机张量\n",
    "\n",
    "#均匀分布随机\n",
    "tf.random.set_seed(1.0)\n",
    "vec_a = tf.random.uniform([5], minval=0, maxval=10)\n",
    "\n",
    "#正态分布随机\n",
    "m_b = tf.random.normal([3, 3], mean=0.0, stddev=1.0)\n",
    "\n",
    "#正态分布随机，剔除2倍方差以外数据重新生成\n",
    "m_c = tf.random.truncated_normal((4, 4), mean=0.0, stddev=1.0, dtype=tf.float32)\n",
    "\n",
    "\n",
    "print(f\"【vec_a】 shape = {vec_a.shape}\")\n",
    "print(f\"【vec_a】 =\\n{vec_a}\")\n",
    "print()\n",
    "print(f\"【m_b】 shape = {m_b.shape}\")\n",
    "print(f\"【m_b】 =\\n{m_b}\")\n",
    "print()\n",
    "print(f\"【m_c】 shape = {m_c.shape}\")\n",
    "print(f\"【m_c】 =\\n{m_c}\")\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 通过设置seed，使得不同时间获得相同的随机值\n",
    "tf.random.set_seed(1.0)\n",
    "vec_a = tf.random.uniform([5], minval=0, maxval=10)\n",
    "\n",
    "tf.random.set_seed(10)\n",
    "vec_b = tf.random.uniform([5], minval=0, maxval=10)\n",
    "\n",
    "tf.random.set_seed(1.0)\n",
    "vec_c = tf.random.uniform([5], minval=0, maxval=10)\n",
    "\n",
    "print(f\"【vec_a】 shape = {vec_a.shape}\")\n",
    "print(f\"【vec_a】 =\\n{vec_a}\")\n",
    "print()\n",
    "print(f\"【vec_b】 shape = {vec_b.shape}\")\n",
    "print(f\"【vec_b】 =\\n{vec_b}\")\n",
    "print()\n",
    "print(f\"【vec_c】 shape = {vec_c.shape}\")\n",
    "print(f\"【vec_c】 =\\n{vec_c}\")\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 数据索引 / 切片"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tf.random.set_seed(3)\n",
    "mtx_a = tf.random.uniform([5, 5], minval=0, maxval=10, dtype=tf.int32)\n",
    "\n",
    "mtx_a"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 默认从第一个轴，进行 索引 / 切片\n",
    "\n",
    "# 取 第1行 数据\n",
    "print(mtx_a[0])\n",
    "print()\n",
    "\n",
    "# 取 最后1行 数据\n",
    "print(mtx_a[-1])\n",
    "print()\n",
    "\n",
    "# 取 第2行、第3列 数据\n",
    "print(mtx_a[1][3])\n",
    "print(mtx_a[1, 3])\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 取 第1-3行 的切片数据\n",
    "tf.print(mtx_a[1:4, :])\n",
    "print()\n",
    "tf.print(tf.slice(mtx_a, [1, 0], [3, 5])) # tf.slice(input, begin_vector, size_vector)\n",
    "print()\n",
    "\n",
    "#第1行至最后1行，第0列到最后1列，每隔1列取1列\n",
    "tf.print(mtx_a[1:, ::2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#对变量来说，还可以使用索引和切片修改部分元素\n",
    "x = tf.Variable([[1, 2], [3, 4]], dtype=tf.float32)\n",
    "\n",
    "print(f\"【x】 shape = {x.shape}\")\n",
    "print(f\"【x】 =\\n{x}\")\n",
    "print()\n",
    "x[1, :].assign(tf.constant([0.0, 0.0]))\n",
    "print(f\"【x】 shape = {x.shape}\")\n",
    "print(f\"【x】 =\\n{x}\")\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = tf.random.uniform([3, 3, 3], minval=0, maxval=10, dtype=tf.int32)\n",
    "\n",
    "print(f\"【a】 shape = {a.shape}\")\n",
    "print(f\"【a】 =\\n{a}\")\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#省略号可以表示多个冒号\n",
    "tf.print(a[:, :, 1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 对于不规则的切片提取, 可以使用 tf.gather, tf.gather_nd, tf.boolean_mask\n",
    "\n",
    "# 3个班级，每个班级有 5个学生，每个学生有 3门功课的成绩\n",
    "scores = tf.random.uniform((3, 5, 3), minval=0, maxval=100, dtype=tf.int32)\n",
    "tf.print(scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 抽取每个班级第0个学生，第2个学生，第4个学生的全部成绩\n",
    "p = tf.gather(scores, [0, 2, 4], axis=1)\n",
    "\n",
    "tf.print(p)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 抽取第0个班级第0个学生，第1个班级的第2个学生，第2个班级的第4个学生的全部成绩\n",
    "\n",
    "#indices的长度为采样样本的个数，每个元素为采样位置的坐标\n",
    "s = tf.gather_nd(scores, indices=[(0, 0), (1, 2), (2, 4)])\n",
    "s"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#抽取每个班级第1个学生，第2个学生，第3个学生的全部成绩\n",
    "p = tf.boolean_mask(scores, [False, True, True, True, False], axis=1)\n",
    "tf.print(p)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#利用tf.boolean_mask可以实现布尔索引\n",
    "\n",
    "#找到矩阵中小于0的元素\n",
    "c = tf.constant([[-1, 1, -1], [2, 2, -2], [3, -3, 3]], dtype=tf.float32)\n",
    "tf.print(c, \"\\n\")\n",
    "\n",
    "tf.print(tf.boolean_mask(c, c<0), \"\\n\")\n",
    "print()\n",
    "tf.print(c[c<0]) #布尔索引，为boolean_mask的语法糖形式"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#找到张量中小于0的元素, 将其换成np.nan得到新的张量\n",
    "#tf.where和np.where作用类似，可以理解为if的张量版本\n",
    "\n",
    "c = tf.constant([[-1, 1, -1], [2, 2, -2], [3, -3, 3]], dtype=tf.float32)\n",
    "\n",
    "print(f\"【c】 shape = {c.shape}\")\n",
    "print(f\"【c】 =\\n{c}\")\n",
    "print()\n",
    "\n",
    "#如果where只有一个参数，将返回所有满足条件的位置坐标\n",
    "indices = tf.where(c < 0)\n",
    "\n",
    "print(f\"【indices】 shape = {indices.shape}\")\n",
    "print(f\"【indices】 =\\n{indices}\")\n",
    "print()\n",
    "\n",
    "b = tf.fill(c.shape, 0.0)\n",
    "print(f\"【b】 shape = {b.shape}\")\n",
    "print(f\"【b】 =\\n{b}\")\n",
    "print()\n",
    "\n",
    "a = tf.where(c<0, b, c)\n",
    "print(f\"【a】 shape = {a.shape}\")\n",
    "# print(f\"【a】 =\\n{a}\")\n",
    "print()\n",
    "a"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "c"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cc = tf.scatter_nd([[0, 0], [2, 1]], [c[0, 0], c[2, 1]], c.shape)\n",
    "cc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#将张量的第[0, 0]和[2, 1]两个位置元素替换为0, 得到新的张量\n",
    "d = c - cc\n",
    "d"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#scatter_nd的作用和gather_nd有些相反\n",
    "#可以将某些值插入到一个给定shape的全0的张量的指定位置处。\n",
    "\n",
    "indices = tf.where(c < 0)\n",
    "\n",
    "print(f\"【c】 shape = {c.shape}\")\n",
    "print(f\"【c】 =\\n{c}\")\n",
    "print()\n",
    "print(f\"【indices】 shape = {indices.shape}\")\n",
    "print(f\"【indices】 =\\n{indices}\")\n",
    "print()\n",
    "\n",
    "n = tf.gather_nd(c, indices)\n",
    "print(f\"【n】 shape = {n.shape}\")\n",
    "print(f\"【n】 =\\n{n}\")\n",
    "print()\n",
    "\n",
    "tf.scatter_nd(indices, n, c.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 维度转换"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- **tf.reshape** 可以改变张量的形状。\n",
    "\n",
    "- **tf.squeeze** 可以减少维度。\n",
    "\n",
    "- **tf.expand_dims** 可以增加维度。\n",
    "\n",
    "- **tf.transpose** 可以交换维度。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = tf.random.uniform(shape=[1, 2, 3, 4], minval=0, maxval=255, dtype=tf.int32)\n",
    "print(f\"【a】 shape = {a.shape}\")\n",
    "print(f\"【a】 =\\n{a}\")\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 使用reshape，改变张量形状为 (4,6): 不会改变张量元素的存储顺序\n",
    "b = tf.reshape(a, [4, 6])\n",
    "print(f\"【b】 shape = {b.shape}\")\n",
    "print(f\"【b】 =\\n{b}\")\n",
    "print()\n",
    "\n",
    "# 改回成 [1,3,3,2] 形状的张量\n",
    "c = tf.reshape(b, [1, 2, 3, 4])\n",
    "print(f\"【c】 shape = {c.shape}\")\n",
    "print(f\"【c】 =\\n{c}\")\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 如果张量在某个维度上只有一个元素，利用tf.squeeze可以消除这个维度\n",
    "s = tf.squeeze(a)\n",
    "print(f\"【s】 shape = {s.shape}\")\n",
    "print(f\"【s】 =\\n{s}\")\n",
    "print()\n",
    "\n",
    "# 在第0维插入长度为1的一个维度\n",
    "d = tf.expand_dims(s, axis=0)\n",
    "print(f\"【d】 shape = {d.shape}\")\n",
    "print(f\"【d】 =\\n{d}\")\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Batch, Height, Width, Channel\n",
    "a = tf.random.uniform(shape=[100, 600, 600, 4], minval=0, maxval=255, dtype=tf.int32)\n",
    "print(f\"【a】 shape = {a.shape}\")\n",
    "# print(f\"【a】 =\\n{a}\")\n",
    "print()\n",
    "\n",
    "# 转换成 Channel, Height, Width, Batch\n",
    "s = tf.transpose(a, perm=[3, 1, 2, 0])\n",
    "print(f\"【s】 shape = {s.shape}\")\n",
    "# print(f\"【s】 =\\n{s}\")\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 张量合并 / 分割"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 合并张量"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- **tf.concat**: 拼接张量，不增加张量维度；\n",
    "- **tf.stack**: 堆叠张量，会增加张量维度；"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 张量拼接: tf.concat\n",
    "a = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "b = tf.constant([[5.0, 6.0], [7.0, 8.0]])\n",
    "c = tf.constant([[9.0, 10.0], [11.0, 12.0]])\n",
    "print(f\"【a】 shape = {a.shape}\")\n",
    "print(f\"【a】 =\\n{a}\")\n",
    "print()\n",
    "print(f\"【b】 shape = {b.shape}\")\n",
    "print(f\"【b】 =\\n{b}\")\n",
    "print()\n",
    "print(f\"【c】 shape = {c.shape}\")\n",
    "print(f\"【c】 =\\n{c}\")\n",
    "print()\n",
    "\n",
    "v = tf.concat([a, b, c], axis=0)\n",
    "h = tf.concat([a, b, c], axis=1)\n",
    "\n",
    "print(f\"【v】 shape = {v.shape}\")\n",
    "print(f\"【v】 =\\n{v}\")\n",
    "print()\n",
    "print(f\"【h】 shape = {h.shape}\")\n",
    "print(f\"【h】 =\\n{h}\")\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 张量堆叠: tf.stack\n",
    "v = tf.stack([a, b, c])\n",
    "h = tf.stack([a, b, c], axis=1)\n",
    "\n",
    "print(f\"【v】 shape = {v.shape}\")\n",
    "print(f\"【v】 =\\n{v}\")\n",
    "print()\n",
    "print(f\"【h】 shape = {h.shape}\")\n",
    "print(f\"【h】 =\\n{h}\")\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 分割张量"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "b = tf.constant([[5.0, 6.0], [7.0, 8.0]])\n",
    "c = tf.constant([[9.0, 10.0], [11.0, 12.0]])\n",
    "\n",
    "c = tf.concat([a, b, c], axis=0)\n",
    "c"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#tf.split(value,num_or_size_splits,axis)\n",
    "# 平均分割: 指定分割份数\n",
    "l = tf.split(c, 3, axis=0)\n",
    "for item in l:\n",
    "    print(item)\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 指定分割: 指定每份张量的 元素个数\n",
    "l = tf.split(c, [1, 2, 3], axis=0) #指定每份的记录数量\n",
    "for item in l:\n",
    "    print(item)\n",
    "    print()\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}