{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 低阶API详解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:27:13.845809Z",
     "iopub.status.busy": "2020-06-16T10:27:13.845205Z",
     "iopub.status.idle": "2020-06-16T10:27:15.544042Z",
     "shell.execute_reply": "2020-06-16T10:27:15.543349Z",
     "shell.execute_reply.started": "2020-06-16T10:27:13.845744Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 张量(Tensor)的结构操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**张量结构操作** 如下：\n",
    "- 张量创建；\n",
    "- 索引切片；\n",
    "- 维度变换；\n",
    "- 合并分割；\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:27:17.110832Z",
     "iopub.status.busy": "2020-06-16T10:27:17.110255Z",
     "iopub.status.idle": "2020-06-16T10:27:17.630076Z",
     "shell.execute_reply": "2020-06-16T10:27:17.628954Z",
     "shell.execute_reply.started": "2020-06-16T10:27:17.110769Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a shape = (3,)\n",
      "a = [1. 2. 3.]\n",
      "\n",
      "x shape = ()\n",
      "x = <tf.Variable 'x:0' shape=() dtype=float32, numpy=1.0>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 创建 常量\n",
    "a = tf.constant([1, 2, 3], dtype=tf.float32)\n",
    "\n",
    "# 创建 变量\n",
    "x = tf.Variable(1.0, name=\"x\", dtype=tf.float32)\n",
    "\n",
    "tf.print(f\"a shape = {a.shape}\")\n",
    "tf.print(f\"a = {a}\")\n",
    "print()\n",
    "tf.print(f\"x shape = {x.shape}\")\n",
    "tf.print(f\"x = {x}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:27:17.948654Z",
     "iopub.status.busy": "2020-06-16T10:27:17.948297Z",
     "iopub.status.idle": "2020-06-16T10:27:17.960646Z",
     "shell.execute_reply": "2020-06-16T10:27:17.959205Z",
     "shell.execute_reply.started": "2020-06-16T10:27:17.948610Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vec_a shape = (5,)\n",
      "vec_a =\n",
      "[1 3 5 7 9]\n",
      "\n",
      "vec_b shape = (10,)\n",
      "vec_b =\n",
      "[0.        0.6977778 1.3955556 2.0933335 2.7911112 3.488889  4.186667\n",
      " 4.8844447 5.5822225 6.28     ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 创建 Vector(一维张量)\n",
    "\n",
    "# 1. \n",
    "vec_a = tf.range(1, 10, delta=2)\n",
    "\n",
    "# 2. \n",
    "vec_b = tf.linspace(0.0, 2 * 3.14, 10)\n",
    "\n",
    "print(f\"vec_a shape = {vec_a.shape}\")\n",
    "print(f\"vec_a =\\n{vec_a}\")\n",
    "print()\n",
    "print(f\"vec_b shape = {vec_b.shape}\")\n",
    "print(f\"vec_b =\\n{vec_b}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:27:18.832639Z",
     "iopub.status.busy": "2020-06-16T10:27:18.832227Z",
     "iopub.status.idle": "2020-06-16T10:27:18.851825Z",
     "shell.execute_reply": "2020-06-16T10:27:18.850528Z",
     "shell.execute_reply.started": "2020-06-16T10:27:18.832586Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【m_ones】 shape = (2, 2)\n",
      "【m_ones】 =\n",
      "[[1. 1.]\n",
      " [1. 1.]]\n",
      "\n",
      "【m_zeros】 shape = (3, 3)\n",
      "【m_zeros】 =\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "\n",
      "【m_zeros_1】 shape = (2, 2)\n",
      "【m_zeros_1】 =\n",
      "[[0. 0.]\n",
      " [0. 0.]]\n",
      "\n",
      "【m_zeros_2】 shape = (3, 2)\n",
      "【m_zeros_2】 =\n",
      "[[5 5]\n",
      " [5 5]\n",
      " [5 5]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 创建 Matrix(二维张量)\n",
    "\n",
    "# 1. \n",
    "m_ones = tf.ones([2, 2])\n",
    "\n",
    "m_zeros = tf.zeros([3, 3])\n",
    "\n",
    "m_zeros_1 = tf.zeros_like(m_ones, dtype=tf.float32)\n",
    "\n",
    "m_zeros_2 = tf.fill((3, 2), 5)\n",
    "\n",
    "\n",
    "print(f\"【m_ones】 shape = {m_ones.shape}\")\n",
    "print(f\"【m_ones】 =\\n{m_ones}\")\n",
    "print()\n",
    "print(f\"【m_zeros】 shape = {m_zeros.shape}\")\n",
    "print(f\"【m_zeros】 =\\n{m_zeros}\")\n",
    "print()\n",
    "print(f\"【m_zeros_1】 shape = {m_zeros_1.shape}\")\n",
    "print(f\"【m_zeros_1】 =\\n{m_zeros_1}\")\n",
    "print()\n",
    "print(f\"【m_zeros_2】 shape = {m_zeros_2.shape}\")\n",
    "print(f\"【m_zeros_2】 =\\n{m_zeros_2}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:27:19.691974Z",
     "iopub.status.busy": "2020-06-16T10:27:19.691589Z",
     "iopub.status.idle": "2020-06-16T10:27:19.703733Z",
     "shell.execute_reply": "2020-06-16T10:27:19.702566Z",
     "shell.execute_reply.started": "2020-06-16T10:27:19.691921Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【m_eye】 shape = (3, 3)\n",
      "【m_eye】 =\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n",
      "\n",
      "【m_diag】 shape = (3, 3)\n",
      "【m_diag】 =\n",
      "[[1 0 0]\n",
      " [0 2 0]\n",
      " [0 0 3]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 特殊矩阵\n",
    "# 单位矩阵\n",
    "m_eye = tf.eye(3, 3)\n",
    "\n",
    "# 对角阵\n",
    "m_diag = tf.linalg.diag([1, 2, 3])\n",
    "\n",
    "print(f\"【m_eye】 shape = {m_eye.shape}\")\n",
    "print(f\"【m_eye】 =\\n{m_eye}\")\n",
    "print()\n",
    "print(f\"【m_diag】 shape = {m_diag.shape}\")\n",
    "print(f\"【m_diag】 =\\n{m_diag}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:27:20.566870Z",
     "iopub.status.busy": "2020-06-16T10:27:20.566481Z",
     "iopub.status.idle": "2020-06-16T10:27:20.585360Z",
     "shell.execute_reply": "2020-06-16T10:27:20.584104Z",
     "shell.execute_reply.started": "2020-06-16T10:27:20.566819Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【vec_a】 shape = (5,)\n",
      "【vec_a】 =\n",
      "[1.6513085 9.014812  6.309742  4.345461  2.9193902]\n",
      "\n",
      "【m_b】 shape = (3, 3)\n",
      "【m_b】 =\n",
      "[[ 0.40308788 -1.0880208  -0.06309535]\n",
      " [ 1.3365567   0.7117601  -0.48928645]\n",
      " [-0.7642213  -1.0372486  -1.2519338 ]]\n",
      "\n",
      "【m_c】 shape = (4, 4)\n",
      "【m_c】 =\n",
      "[[-0.45701224 -0.40686727  0.72857773 -0.8929778 ]\n",
      " [-0.36940458  0.32348856  1.1938332   0.88829905]\n",
      " [ 1.259856   -1.9595189  -0.2022444   0.2944969 ]\n",
      " [-0.46872804  1.294942    1.4814218   0.08109535]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 初始化 随机张量\n",
    "\n",
    "#均匀分布随机\n",
    "tf.random.set_seed(1.0)\n",
    "vec_a = tf.random.uniform([5], minval=0, maxval=10)\n",
    "\n",
    "#正态分布随机\n",
    "m_b = tf.random.normal([3, 3], mean=0.0, stddev=1.0)\n",
    "\n",
    "#正态分布随机，剔除2倍方差以外数据重新生成\n",
    "m_c = tf.random.truncated_normal((4, 4), mean=0.0, stddev=1.0, dtype=tf.float32)\n",
    "\n",
    "\n",
    "print(f\"【vec_a】 shape = {vec_a.shape}\")\n",
    "print(f\"【vec_a】 =\\n{vec_a}\")\n",
    "print()\n",
    "print(f\"【m_b】 shape = {m_b.shape}\")\n",
    "print(f\"【m_b】 =\\n{m_b}\")\n",
    "print()\n",
    "print(f\"【m_c】 shape = {m_c.shape}\")\n",
    "print(f\"【m_c】 =\\n{m_c}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:27:21.653531Z",
     "iopub.status.busy": "2020-06-16T10:27:21.653075Z",
     "iopub.status.idle": "2020-06-16T10:27:21.672749Z",
     "shell.execute_reply": "2020-06-16T10:27:21.671583Z",
     "shell.execute_reply.started": "2020-06-16T10:27:21.653473Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【vec_a】 shape = (5,)\n",
      "【vec_a】 =\n",
      "[1.6513085 9.014812  6.309742  4.345461  2.9193902]\n",
      "\n",
      "【vec_b】 shape = (5,)\n",
      "【vec_b】 =\n",
      "[6.4415097 8.082472  8.976547  6.3689017 6.270969 ]\n",
      "\n",
      "【vec_c】 shape = (5,)\n",
      "【vec_c】 =\n",
      "[1.6513085 9.014812  6.309742  4.345461  2.9193902]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 通过设置seed，使得不同时间获得相同的随机值\n",
    "tf.random.set_seed(1.0)\n",
    "vec_a = tf.random.uniform([5], minval=0, maxval=10)\n",
    "\n",
    "tf.random.set_seed(10)\n",
    "vec_b = tf.random.uniform([5], minval=0, maxval=10)\n",
    "\n",
    "tf.random.set_seed(1.0)\n",
    "vec_c = tf.random.uniform([5], minval=0, maxval=10)\n",
    "\n",
    "print(f\"【vec_a】 shape = {vec_a.shape}\")\n",
    "print(f\"【vec_a】 =\\n{vec_a}\")\n",
    "print()\n",
    "print(f\"【vec_b】 shape = {vec_b.shape}\")\n",
    "print(f\"【vec_b】 =\\n{vec_b}\")\n",
    "print()\n",
    "print(f\"【vec_c】 shape = {vec_c.shape}\")\n",
    "print(f\"【vec_c】 =\\n{vec_c}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据索引 / 切片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:27:23.174638Z",
     "iopub.status.busy": "2020-06-16T10:27:23.174087Z",
     "iopub.status.idle": "2020-06-16T10:27:23.186348Z",
     "shell.execute_reply": "2020-06-16T10:27:23.185034Z",
     "shell.execute_reply.started": "2020-06-16T10:27:23.174576Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 5), dtype=int32, numpy=\n",
       "array([[4, 7, 4, 2, 9],\n",
       "       [9, 1, 2, 4, 7],\n",
       "       [7, 2, 7, 4, 0],\n",
       "       [9, 6, 9, 7, 2],\n",
       "       [3, 7, 0, 0, 3]], dtype=int32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(3)\n",
    "mtx_a = tf.random.uniform([5, 5], minval=0, maxval=10, dtype=tf.int32)\n",
    "\n",
    "mtx_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:27:23.963415Z",
     "iopub.status.busy": "2020-06-16T10:27:23.963020Z",
     "iopub.status.idle": "2020-06-16T10:27:23.975090Z",
     "shell.execute_reply": "2020-06-16T10:27:23.974022Z",
     "shell.execute_reply.started": "2020-06-16T10:27:23.963361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([4 7 4 2 9], shape=(5,), dtype=int32)\n",
      "\n",
      "tf.Tensor([3 7 0 0 3], shape=(5,), dtype=int32)\n",
      "\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 默认从第一个轴，进行 索引 / 切片\n",
    "\n",
    "# 取 第1行 数据\n",
    "print(mtx_a[0])\n",
    "print()\n",
    "\n",
    "# 取 最后1行 数据\n",
    "print(mtx_a[-1])\n",
    "print()\n",
    "\n",
    "# 取 第2行、第3列 数据\n",
    "print(mtx_a[1][3])\n",
    "print(mtx_a[1, 3])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:27:24.799147Z",
     "iopub.status.busy": "2020-06-16T10:27:24.798717Z",
     "iopub.status.idle": "2020-06-16T10:27:24.815190Z",
     "shell.execute_reply": "2020-06-16T10:27:24.814069Z",
     "shell.execute_reply.started": "2020-06-16T10:27:24.799087Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9 1 2 4 7]\n",
      " [7 2 7 4 0]\n",
      " [9 6 9 7 2]]\n",
      "\n",
      "[[9 1 2 4 7]\n",
      " [7 2 7 4 0]\n",
      " [9 6 9 7 2]]\n",
      "\n",
      "[[9 2 7]\n",
      " [7 7 0]\n",
      " [9 9 2]\n",
      " [3 0 3]]\n"
     ]
    }
   ],
   "source": [
    "# 取 第1-3行 的切片数据\n",
    "tf.print(mtx_a[1:4, :])\n",
    "print()\n",
    "tf.print(tf.slice(mtx_a, [1, 0], [3, 5])) # tf.slice(input, begin_vector, size_vector)\n",
    "print()\n",
    "\n",
    "#第1行至最后1行，第0列到最后1列，每隔1列取1列\n",
    "tf.print(mtx_a[1:, ::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:27:25.613188Z",
     "iopub.status.busy": "2020-06-16T10:27:25.612757Z",
     "iopub.status.idle": "2020-06-16T10:27:25.629101Z",
     "shell.execute_reply": "2020-06-16T10:27:25.627939Z",
     "shell.execute_reply.started": "2020-06-16T10:27:25.613132Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【x】 shape = (2, 2)\n",
      "【x】 =\n",
      "<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
      "array([[1., 2.],\n",
      "       [3., 4.]], dtype=float32)>\n",
      "\n",
      "【x】 shape = (2, 2)\n",
      "【x】 =\n",
      "<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
      "array([[1., 2.],\n",
      "       [0., 0.]], dtype=float32)>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#对变量来说，还可以使用索引和切片修改部分元素\n",
    "x = tf.Variable([[1, 2], [3, 4]], dtype=tf.float32)\n",
    "\n",
    "print(f\"【x】 shape = {x.shape}\")\n",
    "print(f\"【x】 =\\n{x}\")\n",
    "print()\n",
    "x[1, :].assign(tf.constant([0.0, 0.0]))\n",
    "print(f\"【x】 shape = {x.shape}\")\n",
    "print(f\"【x】 =\\n{x}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:27:26.505539Z",
     "iopub.status.busy": "2020-06-16T10:27:26.504994Z",
     "iopub.status.idle": "2020-06-16T10:27:26.516531Z",
     "shell.execute_reply": "2020-06-16T10:27:26.515268Z",
     "shell.execute_reply.started": "2020-06-16T10:27:26.505478Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【a】 shape = (3, 3, 3)\n",
      "【a】 =\n",
      "[[[7 3 9]\n",
      "  [9 0 7]\n",
      "  [9 6 7]]\n",
      "\n",
      " [[1 3 3]\n",
      "  [0 8 1]\n",
      "  [3 1 0]]\n",
      "\n",
      " [[4 0 6]\n",
      "  [6 2 2]\n",
      "  [7 9 5]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = tf.random.uniform([3, 3, 3], minval=0, maxval=10, dtype=tf.int32)\n",
    "\n",
    "print(f\"【a】 shape = {a.shape}\")\n",
    "print(f\"【a】 =\\n{a}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:27:27.372520Z",
     "iopub.status.busy": "2020-06-16T10:27:27.372074Z",
     "iopub.status.idle": "2020-06-16T10:27:27.380714Z",
     "shell.execute_reply": "2020-06-16T10:27:27.379518Z",
     "shell.execute_reply.started": "2020-06-16T10:27:27.372463Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 0 6]\n",
      " [3 8 1]\n",
      " [0 2 9]]\n"
     ]
    }
   ],
   "source": [
    "#省略号可以表示多个冒号\n",
    "tf.print(a[:, :, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:27:28.274521Z",
     "iopub.status.busy": "2020-06-16T10:27:28.274134Z",
     "iopub.status.idle": "2020-06-16T10:27:28.283117Z",
     "shell.execute_reply": "2020-06-16T10:27:28.282013Z",
     "shell.execute_reply.started": "2020-06-16T10:27:28.274471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[52 82 66]\n",
      "  [55 17 86]\n",
      "  [14 8 36]\n",
      "  [94 16 13]\n",
      "  [78 41 77]]\n",
      "\n",
      " [[53 51 93]\n",
      "  [22 91 56]\n",
      "  [73 31 18]\n",
      "  [9 93 87]\n",
      "  [21 25 40]]\n",
      "\n",
      " [[16 76 32]\n",
      "  [49 88 24]\n",
      "  [80 70 46]\n",
      "  [72 63 96]\n",
      "  [16 44 31]]]\n"
     ]
    }
   ],
   "source": [
    "# 对于不规则的切片提取, 可以使用 tf.gather, tf.gather_nd, tf.boolean_mask\n",
    "\n",
    "# 3个班级，每个班级有 5个学生，每个学生有 3门功课的成绩\n",
    "scores = tf.random.uniform((3, 5, 3), minval=0, maxval=100, dtype=tf.int32)\n",
    "tf.print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:27:29.145270Z",
     "iopub.status.busy": "2020-06-16T10:27:29.144847Z",
     "iopub.status.idle": "2020-06-16T10:27:29.154048Z",
     "shell.execute_reply": "2020-06-16T10:27:29.152667Z",
     "shell.execute_reply.started": "2020-06-16T10:27:29.145213Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[52 82 66]\n",
      "  [14 8 36]\n",
      "  [78 41 77]]\n",
      "\n",
      " [[53 51 93]\n",
      "  [73 31 18]\n",
      "  [21 25 40]]\n",
      "\n",
      " [[16 76 32]\n",
      "  [80 70 46]\n",
      "  [16 44 31]]]\n"
     ]
    }
   ],
   "source": [
    "# 抽取每个班级第0个学生，第2个学生，第4个学生的全部成绩\n",
    "p = tf.gather(scores, [0, 2, 4], axis=1)\n",
    "\n",
    "tf.print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:27:29.986559Z",
     "iopub.status.busy": "2020-06-16T10:27:29.986150Z",
     "iopub.status.idle": "2020-06-16T10:27:29.996180Z",
     "shell.execute_reply": "2020-06-16T10:27:29.994869Z",
     "shell.execute_reply.started": "2020-06-16T10:27:29.986507Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[52, 82, 66],\n",
       "       [73, 31, 18],\n",
       "       [16, 44, 31]], dtype=int32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 抽取第0个班级第0个学生，第1个班级的第2个学生，第2个班级的第4个学生的全部成绩\n",
    "\n",
    "#indices的长度为采样样本的个数，每个元素为采样位置的坐标\n",
    "s = tf.gather_nd(scores, indices=[(0, 0), (1, 2), (2, 4)])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:27:30.834999Z",
     "iopub.status.busy": "2020-06-16T10:27:30.834620Z",
     "iopub.status.idle": "2020-06-16T10:27:30.847173Z",
     "shell.execute_reply": "2020-06-16T10:27:30.846064Z",
     "shell.execute_reply.started": "2020-06-16T10:27:30.834949Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[55 17 86]\n",
      "  [14 8 36]\n",
      "  [94 16 13]]\n",
      "\n",
      " [[22 91 56]\n",
      "  [73 31 18]\n",
      "  [9 93 87]]\n",
      "\n",
      " [[49 88 24]\n",
      "  [80 70 46]\n",
      "  [72 63 96]]]\n"
     ]
    }
   ],
   "source": [
    "#抽取每个班级第1个学生，第2个学生，第3个学生的全部成绩\n",
    "p = tf.boolean_mask(scores, [False, True, True, True, False], axis=1)\n",
    "tf.print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:27:31.696077Z",
     "iopub.status.busy": "2020-06-16T10:27:31.695517Z",
     "iopub.status.idle": "2020-06-16T10:27:31.716951Z",
     "shell.execute_reply": "2020-06-16T10:27:31.715877Z",
     "shell.execute_reply.started": "2020-06-16T10:27:31.696013Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1 1 -1]\n",
      " [2 2 -2]\n",
      " [3 -3 3]] \n",
      "\n",
      "[-1 -1 -2 -3] \n",
      "\n",
      "\n",
      "[-1 -1 -2 -3]\n"
     ]
    }
   ],
   "source": [
    "#利用tf.boolean_mask可以实现布尔索引\n",
    "\n",
    "#找到矩阵中小于0的元素\n",
    "c = tf.constant([[-1, 1, -1], [2, 2, -2], [3, -3, 3]], dtype=tf.float32)\n",
    "tf.print(c, \"\\n\")\n",
    "\n",
    "tf.print(tf.boolean_mask(c, c<0), \"\\n\") \n",
    "print()\n",
    "tf.print(c[c<0]) #布尔索引，为boolean_mask的语法糖形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:27:32.559573Z",
     "iopub.status.busy": "2020-06-16T10:27:32.559028Z",
     "iopub.status.idle": "2020-06-16T10:27:32.584213Z",
     "shell.execute_reply": "2020-06-16T10:27:32.583099Z",
     "shell.execute_reply.started": "2020-06-16T10:27:32.559513Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【c】 shape = (3, 3)\n",
      "【c】 =\n",
      "[[-1.  1. -1.]\n",
      " [ 2.  2. -2.]\n",
      " [ 3. -3.  3.]]\n",
      "\n",
      "【indices】 shape = (4, 2)\n",
      "【indices】 =\n",
      "[[0 0]\n",
      " [0 2]\n",
      " [1 2]\n",
      " [2 1]]\n",
      "\n",
      "【b】 shape = (3, 3)\n",
      "【b】 =\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "\n",
      "【a】 shape = (3, 3)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0., 1., 0.],\n",
       "       [2., 2., 0.],\n",
       "       [3., 0., 3.]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#找到张量中小于0的元素, 将其换成np.nan得到新的张量\n",
    "#tf.where和np.where作用类似，可以理解为if的张量版本\n",
    "\n",
    "c = tf.constant([[-1, 1, -1], [2, 2, -2], [3, -3, 3]], dtype=tf.float32)\n",
    "\n",
    "print(f\"【c】 shape = {c.shape}\")\n",
    "print(f\"【c】 =\\n{c}\")\n",
    "print()\n",
    "\n",
    "#如果where只有一个参数，将返回所有满足条件的位置坐标\n",
    "indices = tf.where(c < 0)\n",
    "\n",
    "print(f\"【indices】 shape = {indices.shape}\")\n",
    "print(f\"【indices】 =\\n{indices}\")\n",
    "print()\n",
    "\n",
    "b = tf.fill(c.shape, 0.0)\n",
    "print(f\"【b】 shape = {b.shape}\")\n",
    "print(f\"【b】 =\\n{b}\")\n",
    "print()\n",
    "\n",
    "a = tf.where(c<0, b, c) \n",
    "print(f\"【a】 shape = {a.shape}\")\n",
    "# print(f\"【a】 =\\n{a}\")\n",
    "print()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:27:33.434984Z",
     "iopub.status.busy": "2020-06-16T10:27:33.434560Z",
     "iopub.status.idle": "2020-06-16T10:27:33.442917Z",
     "shell.execute_reply": "2020-06-16T10:27:33.441691Z",
     "shell.execute_reply.started": "2020-06-16T10:27:33.434925Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[-1.,  1., -1.],\n",
       "       [ 2.,  2., -2.],\n",
       "       [ 3., -3.,  3.]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:27:34.276819Z",
     "iopub.status.busy": "2020-06-16T10:27:34.276405Z",
     "iopub.status.idle": "2020-06-16T10:27:34.287503Z",
     "shell.execute_reply": "2020-06-16T10:27:34.286402Z",
     "shell.execute_reply.started": "2020-06-16T10:27:34.276753Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[-1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0., -3.,  0.]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc = tf.scatter_nd([[0, 0], [2, 1]], [c[0, 0], c[2, 1]], c.shape)\n",
    "cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:27:35.112246Z",
     "iopub.status.busy": "2020-06-16T10:27:35.111820Z",
     "iopub.status.idle": "2020-06-16T10:27:35.120590Z",
     "shell.execute_reply": "2020-06-16T10:27:35.119455Z",
     "shell.execute_reply.started": "2020-06-16T10:27:35.112189Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[ 0.,  1., -1.],\n",
       "       [ 2.,  2., -2.],\n",
       "       [ 3.,  0.,  3.]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#将张量的第[0, 0]和[2, 1]两个位置元素替换为0, 得到新的张量\n",
    "d = c - cc\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:27:35.934578Z",
     "iopub.status.busy": "2020-06-16T10:27:35.934172Z",
     "iopub.status.idle": "2020-06-16T10:27:35.952441Z",
     "shell.execute_reply": "2020-06-16T10:27:35.951425Z",
     "shell.execute_reply.started": "2020-06-16T10:27:35.934525Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【c】 shape = (3, 3)\n",
      "【c】 =\n",
      "[[-1.  1. -1.]\n",
      " [ 2.  2. -2.]\n",
      " [ 3. -3.  3.]]\n",
      "\n",
      "【indices】 shape = (4, 2)\n",
      "【indices】 =\n",
      "[[0 0]\n",
      " [0 2]\n",
      " [1 2]\n",
      " [2 1]]\n",
      "\n",
      "【n】 shape = (4,)\n",
      "【n】 =\n",
      "[-1. -1. -2. -3.]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[-1.,  0., -1.],\n",
       "       [ 0.,  0., -2.],\n",
       "       [ 0., -3.,  0.]], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scatter_nd的作用和gather_nd有些相反\n",
    "#可以将某些值插入到一个给定shape的全0的张量的指定位置处。\n",
    "\n",
    "indices = tf.where(c < 0)\n",
    "\n",
    "print(f\"【c】 shape = {c.shape}\")\n",
    "print(f\"【c】 =\\n{c}\")\n",
    "print()\n",
    "print(f\"【indices】 shape = {indices.shape}\")\n",
    "print(f\"【indices】 =\\n{indices}\")\n",
    "print()\n",
    "\n",
    "n = tf.gather_nd(c, indices)\n",
    "print(f\"【n】 shape = {n.shape}\")\n",
    "print(f\"【n】 =\\n{n}\")\n",
    "print()\n",
    "\n",
    "tf.scatter_nd(indices, n, c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 维度转换"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **tf.reshape** 可以改变张量的形状。\n",
    "\n",
    "- **tf.squeeze** 可以减少维度。\n",
    "\n",
    "- **tf.expand_dims** 可以增加维度。\n",
    "\n",
    "- **tf.transpose** 可以交换维度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:27:38.428256Z",
     "iopub.status.busy": "2020-06-16T10:27:38.427815Z",
     "iopub.status.idle": "2020-06-16T10:27:38.439625Z",
     "shell.execute_reply": "2020-06-16T10:27:38.438182Z",
     "shell.execute_reply.started": "2020-06-16T10:27:38.428198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【a】 shape = (1, 2, 3, 4)\n",
      "【a】 =\n",
      "[[[[100  44 181  14]\n",
      "   [ 90  53 205 141]\n",
      "   [ 14  24 239  46]]\n",
      "\n",
      "  [[225 174 212  78]\n",
      "   [ 14 144 209 106]\n",
      "   [165  41  44  38]]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = tf.random.uniform(shape=[1, 2, 3, 4], minval=0, maxval=255, dtype=tf.int32)\n",
    "print(f\"【a】 shape = {a.shape}\")\n",
    "print(f\"【a】 =\\n{a}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:27:39.286878Z",
     "iopub.status.busy": "2020-06-16T10:27:39.286350Z",
     "iopub.status.idle": "2020-06-16T10:27:39.298840Z",
     "shell.execute_reply": "2020-06-16T10:27:39.297608Z",
     "shell.execute_reply.started": "2020-06-16T10:27:39.286826Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【b】 shape = (4, 6)\n",
      "【b】 =\n",
      "[[100  44 181  14  90  53]\n",
      " [205 141  14  24 239  46]\n",
      " [225 174 212  78  14 144]\n",
      " [209 106 165  41  44  38]]\n",
      "\n",
      "【c】 shape = (1, 2, 3, 4)\n",
      "【c】 =\n",
      "[[[[100  44 181  14]\n",
      "   [ 90  53 205 141]\n",
      "   [ 14  24 239  46]]\n",
      "\n",
      "  [[225 174 212  78]\n",
      "   [ 14 144 209 106]\n",
      "   [165  41  44  38]]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 使用reshape，改变张量形状为 (4,6): 不会改变张量元素的存储顺序\n",
    "b = tf.reshape(a, [4, 6])\n",
    "print(f\"【b】 shape = {b.shape}\")\n",
    "print(f\"【b】 =\\n{b}\")\n",
    "print()\n",
    "\n",
    "# 改回成 [1,3,3,2] 形状的张量\n",
    "c = tf.reshape(b, [1, 2, 3, 4])\n",
    "print(f\"【c】 shape = {c.shape}\")\n",
    "print(f\"【c】 =\\n{c}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:27:40.352724Z",
     "iopub.status.busy": "2020-06-16T10:27:40.352291Z",
     "iopub.status.idle": "2020-06-16T10:27:40.364740Z",
     "shell.execute_reply": "2020-06-16T10:27:40.363531Z",
     "shell.execute_reply.started": "2020-06-16T10:27:40.352669Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【s】 shape = (2, 3, 4)\n",
      "【s】 =\n",
      "[[[100  44 181  14]\n",
      "  [ 90  53 205 141]\n",
      "  [ 14  24 239  46]]\n",
      "\n",
      " [[225 174 212  78]\n",
      "  [ 14 144 209 106]\n",
      "  [165  41  44  38]]]\n",
      "\n",
      "【d】 shape = (1, 2, 3, 4)\n",
      "【d】 =\n",
      "[[[[100  44 181  14]\n",
      "   [ 90  53 205 141]\n",
      "   [ 14  24 239  46]]\n",
      "\n",
      "  [[225 174 212  78]\n",
      "   [ 14 144 209 106]\n",
      "   [165  41  44  38]]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 如果张量在某个维度上只有一个元素，利用tf.squeeze可以消除这个维度\n",
    "s = tf.squeeze(a)\n",
    "print(f\"【s】 shape = {s.shape}\")\n",
    "print(f\"【s】 =\\n{s}\")\n",
    "print()\n",
    "\n",
    "# 在第0维插入长度为1的一个维度\n",
    "d = tf.expand_dims(s, axis=0)\n",
    "print(f\"【d】 shape = {d.shape}\")\n",
    "print(f\"【d】 =\\n{d}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:27:41.046114Z",
     "iopub.status.busy": "2020-06-16T10:27:41.045614Z",
     "iopub.status.idle": "2020-06-16T10:27:41.293745Z",
     "shell.execute_reply": "2020-06-16T10:27:41.293053Z",
     "shell.execute_reply.started": "2020-06-16T10:27:41.046054Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【a】 shape = (100, 600, 600, 4)\n",
      "\n",
      "【s】 shape = (4, 600, 600, 100)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Batch, Height, Width, Channel\n",
    "a = tf.random.uniform(shape=[100, 600, 600, 4], minval=0, maxval=255, dtype=tf.int32)\n",
    "print(f\"【a】 shape = {a.shape}\")\n",
    "# print(f\"【a】 =\\n{a}\")\n",
    "print()\n",
    "\n",
    "# 转换成 Channel, Height, Width, Batch\n",
    "s = tf.transpose(a, perm=[3, 1, 2, 0])\n",
    "print(f\"【s】 shape = {s.shape}\")\n",
    "# print(f\"【s】 =\\n{s}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 张量合并 / 分割"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 合并张量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **tf.concat**: 拼接张量，不增加张量维度；\n",
    "- **tf.stack**: 堆叠张量，会增加张量维度；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:27:44.331484Z",
     "iopub.status.busy": "2020-06-16T10:27:44.330912Z",
     "iopub.status.idle": "2020-06-16T10:27:44.358483Z",
     "shell.execute_reply": "2020-06-16T10:27:44.357190Z",
     "shell.execute_reply.started": "2020-06-16T10:27:44.331418Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【a】 shape = (2, 2)\n",
      "【a】 =\n",
      "[[1. 2.]\n",
      " [3. 4.]]\n",
      "\n",
      "【b】 shape = (2, 2)\n",
      "【b】 =\n",
      "[[5. 6.]\n",
      " [7. 8.]]\n",
      "\n",
      "【c】 shape = (2, 2)\n",
      "【c】 =\n",
      "[[ 9. 10.]\n",
      " [11. 12.]]\n",
      "\n",
      "【v】 shape = (6, 2)\n",
      "【v】 =\n",
      "[[ 1.  2.]\n",
      " [ 3.  4.]\n",
      " [ 5.  6.]\n",
      " [ 7.  8.]\n",
      " [ 9. 10.]\n",
      " [11. 12.]]\n",
      "\n",
      "【h】 shape = (2, 6)\n",
      "【h】 =\n",
      "[[ 1.  2.  5.  6.  9. 10.]\n",
      " [ 3.  4.  7.  8. 11. 12.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 张量拼接: tf.concat\n",
    "a = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "b = tf.constant([[5.0, 6.0], [7.0, 8.0]])\n",
    "c = tf.constant([[9.0, 10.0], [11.0, 12.0]])\n",
    "print(f\"【a】 shape = {a.shape}\")\n",
    "print(f\"【a】 =\\n{a}\")\n",
    "print()\n",
    "print(f\"【b】 shape = {b.shape}\")\n",
    "print(f\"【b】 =\\n{b}\")\n",
    "print()\n",
    "print(f\"【c】 shape = {c.shape}\")\n",
    "print(f\"【c】 =\\n{c}\")\n",
    "print()\n",
    "\n",
    "v = tf.concat([a, b, c], axis=0)\n",
    "h = tf.concat([a, b, c], axis=1)\n",
    "\n",
    "print(f\"【v】 shape = {v.shape}\")\n",
    "print(f\"【v】 =\\n{v}\")\n",
    "print()\n",
    "print(f\"【h】 shape = {h.shape}\")\n",
    "print(f\"【h】 =\\n{h}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:27:45.226330Z",
     "iopub.status.busy": "2020-06-16T10:27:45.225943Z",
     "iopub.status.idle": "2020-06-16T10:27:45.238128Z",
     "shell.execute_reply": "2020-06-16T10:27:45.236929Z",
     "shell.execute_reply.started": "2020-06-16T10:27:45.226264Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【v】 shape = (3, 2, 2)\n",
      "【v】 =\n",
      "[[[ 1.  2.]\n",
      "  [ 3.  4.]]\n",
      "\n",
      " [[ 5.  6.]\n",
      "  [ 7.  8.]]\n",
      "\n",
      " [[ 9. 10.]\n",
      "  [11. 12.]]]\n",
      "\n",
      "【h】 shape = (2, 3, 2)\n",
      "【h】 =\n",
      "[[[ 1.  2.]\n",
      "  [ 5.  6.]\n",
      "  [ 9. 10.]]\n",
      "\n",
      " [[ 3.  4.]\n",
      "  [ 7.  8.]\n",
      "  [11. 12.]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 张量堆叠: tf.stack\n",
    "v = tf.stack([a, b, c])\n",
    "h = tf.stack([a, b, c], axis=1)\n",
    "\n",
    "print(f\"【v】 shape = {v.shape}\")\n",
    "print(f\"【v】 =\\n{v}\")\n",
    "print()\n",
    "print(f\"【h】 shape = {h.shape}\")\n",
    "print(f\"【h】 =\\n{h}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 分割张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:27:46.876720Z",
     "iopub.status.busy": "2020-06-16T10:27:46.876268Z",
     "iopub.status.idle": "2020-06-16T10:27:46.890697Z",
     "shell.execute_reply": "2020-06-16T10:27:46.889414Z",
     "shell.execute_reply.started": "2020-06-16T10:27:46.876662Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 2), dtype=float32, numpy=\n",
       "array([[ 1.,  2.],\n",
       "       [ 3.,  4.],\n",
       "       [ 5.,  6.],\n",
       "       [ 7.,  8.],\n",
       "       [ 9., 10.],\n",
       "       [11., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "b = tf.constant([[5.0, 6.0], [7.0, 8.0]])\n",
    "c = tf.constant([[9.0, 10.0], [11.0, 12.0]])\n",
    "\n",
    "c = tf.concat([a, b, c], axis=0)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:27:47.743815Z",
     "iopub.status.busy": "2020-06-16T10:27:47.743371Z",
     "iopub.status.idle": "2020-06-16T10:27:47.754440Z",
     "shell.execute_reply": "2020-06-16T10:27:47.752809Z",
     "shell.execute_reply.started": "2020-06-16T10:27:47.743758Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 2.]\n",
      " [3. 4.]], shape=(2, 2), dtype=float32)\n",
      "\n",
      "tf.Tensor(\n",
      "[[5. 6.]\n",
      " [7. 8.]], shape=(2, 2), dtype=float32)\n",
      "\n",
      "tf.Tensor(\n",
      "[[ 9. 10.]\n",
      " [11. 12.]], shape=(2, 2), dtype=float32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#tf.split(value,num_or_size_splits,axis)\n",
    "# 平均分割: 指定分割份数\n",
    "l = tf.split(c, 3, axis=0)\n",
    "for item in l:\n",
    "    print(item)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:27:48.610265Z",
     "iopub.status.busy": "2020-06-16T10:27:48.609844Z",
     "iopub.status.idle": "2020-06-16T10:27:48.620902Z",
     "shell.execute_reply": "2020-06-16T10:27:48.619543Z",
     "shell.execute_reply.started": "2020-06-16T10:27:48.610208Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[1. 2.]], shape=(1, 2), dtype=float32)\n",
      "\n",
      "tf.Tensor(\n",
      "[[3. 4.]\n",
      " [5. 6.]], shape=(2, 2), dtype=float32)\n",
      "\n",
      "tf.Tensor(\n",
      "[[ 7.  8.]\n",
      " [ 9. 10.]\n",
      " [11. 12.]], shape=(3, 2), dtype=float32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 指定分割: 指定每份张量的 元素个数\n",
    "l = tf.split(c, [1, 2, 3], axis=0) #指定每份的记录数量\n",
    "for item in l:\n",
    "    print(item)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 张量(Tensor)的数学运算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "张量数学运算主要有：\n",
    "- **标量运算**\n",
    "- **向量运算**\n",
    "- **矩阵运算**\n",
    "- **张量运算的广播机制**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 标量运算\n",
    "\n",
    "加、减、乘、除、乘方，以及三角函数，指数，对数等常见函数，逻辑比较运算符等都是标量运算；\n",
    "\n",
    "【标量运算符】的特点是 **对张量实施逐元素运算**；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:27:51.809683Z",
     "iopub.status.busy": "2020-06-16T10:27:51.809100Z",
     "iopub.status.idle": "2020-06-16T10:27:51.828399Z",
     "shell.execute_reply": "2020-06-16T10:27:51.826784Z",
     "shell.execute_reply.started": "2020-06-16T10:27:51.809619Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【a】 =\n",
      "[[ 1.  2.]\n",
      " [-3.  4.]]\n",
      "\n",
      "【b】 =\n",
      "[[5. 6.]\n",
      " [7. 8.]]\n",
      "\n",
      "【加法】：\n",
      "【c】 =\n",
      "[[ 6.  8.]\n",
      " [ 4. 12.]]\n",
      "\n",
      "【减法】：\n",
      "【c】 =\n",
      "[[ -4.  -4.]\n",
      " [-10.  -4.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([[1.0, 2], [-3, 4.0]])\n",
    "b = tf.constant([[5.0, 6], [7.0, 8.0]])\n",
    "# print(f\"【a】 shape = {a.shape}\")\n",
    "print(f\"【a】 =\\n{a}\")\n",
    "print()\n",
    "# print(f\"【b】 shape = {b.shape}\")\n",
    "print(f\"【b】 =\\n{b}\")\n",
    "print()\n",
    "\n",
    "# 加法\n",
    "print(\"【加法】：\")\n",
    "c = a + b  #运算符重载\n",
    "# print(f\"【c】 shape = {c.shape}\")\n",
    "print(f\"【c】 =\\n{c}\")\n",
    "print()\n",
    "\n",
    "# 减法\n",
    "print(\"【减法】：\")\n",
    "c = a - b  #运算符重载\n",
    "# print(f\"【c】 shape = {c.shape}\")\n",
    "print(f\"【c】 =\\n{c}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:27:52.688739Z",
     "iopub.status.busy": "2020-06-16T10:27:52.688295Z",
     "iopub.status.idle": "2020-06-16T10:27:52.703064Z",
     "shell.execute_reply": "2020-06-16T10:27:52.701924Z",
     "shell.execute_reply.started": "2020-06-16T10:27:52.688681Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【a】 =\n",
      "[[ 1.  2.]\n",
      " [-3.  4.]]\n",
      "\n",
      "【b】 =\n",
      "[[5. 6.]\n",
      " [7. 8.]]\n",
      "\n",
      "【乘法】：\n",
      "【c】 =\n",
      "[[  5.  12.]\n",
      " [-21.  32.]]\n",
      "\n",
      "【除法】：\n",
      "【c】 =\n",
      "[[ 0.2         0.33333334]\n",
      " [-0.42857143  0.5       ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(f\"【a】 shape = {a.shape}\")\n",
    "print(f\"【a】 =\\n{a}\")\n",
    "print()\n",
    "# print(f\"【b】 shape = {b.shape}\")\n",
    "print(f\"【b】 =\\n{b}\")\n",
    "print()\n",
    "\n",
    "# 乘法\n",
    "print(\"【乘法】：\")\n",
    "c = a * b  #运算符重载\n",
    "# print(f\"【c】 shape = {c.shape}\")\n",
    "print(f\"【c】 =\\n{c}\")\n",
    "print()\n",
    "\n",
    "# 除法\n",
    "print(\"【除法】：\")\n",
    "c = a / b  #运算符重载\n",
    "# print(f\"【c】 shape = {c.shape}\")\n",
    "print(f\"【c】 =\\n{c}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:27:53.565963Z",
     "iopub.status.busy": "2020-06-16T10:27:53.565558Z",
     "iopub.status.idle": "2020-06-16T10:27:53.579922Z",
     "shell.execute_reply": "2020-06-16T10:27:53.578769Z",
     "shell.execute_reply.started": "2020-06-16T10:27:53.565910Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【a】 =\n",
      "[[ 1.  2.]\n",
      " [-3.  4.]]\n",
      "\n",
      "【b】 =\n",
      "[[5. 6.]\n",
      " [7. 8.]]\n",
      "\n",
      "【地板除】：\n",
      "【c】 =\n",
      "[[ 0.  1.]\n",
      " [-2.  2.]]\n",
      "\n",
      "【模运算】：\n",
      "【c】 =\n",
      "[[ 1.  2.]\n",
      " [-0.  1.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(f\"【a】 shape = {a.shape}\")\n",
    "print(f\"【a】 =\\n{a}\")\n",
    "print()\n",
    "# print(f\"【b】 shape = {b.shape}\")\n",
    "print(f\"【b】 =\\n{b}\")\n",
    "print()\n",
    "\n",
    "# 地板除\n",
    "print(\"【地板除】：\")\n",
    "c = a // 2\n",
    "# print(f\"【c】 shape = {c.shape}\")\n",
    "print(f\"【c】 =\\n{c}\")\n",
    "print()\n",
    "\n",
    "# 模运算%\n",
    "print(\"【模运算】：\")\n",
    "c = a % 3\n",
    "# print(f\"【c】 shape = {c.shape}\")\n",
    "print(f\"【c】 =\\n{c}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:27:54.432177Z",
     "iopub.status.busy": "2020-06-16T10:27:54.431745Z",
     "iopub.status.idle": "2020-06-16T10:27:54.446898Z",
     "shell.execute_reply": "2020-06-16T10:27:54.445329Z",
     "shell.execute_reply.started": "2020-06-16T10:27:54.432118Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【a】 =\n",
      "[[ 1.  2.]\n",
      " [-3.  4.]]\n",
      "\n",
      "【c】 =\n",
      "[[ 1.  4.]\n",
      " [ 9. 16.]]\n",
      "\n",
      "【c】 =\n",
      "[[1.        1.4142135]\n",
      " [      nan 2.       ]]\n",
      "\n",
      "【c】 =\n",
      "[[1.        1.4142135]\n",
      " [      nan 2.       ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(f\"【a】 shape = {a.shape}\")\n",
    "print(f\"【a】 =\\n{a}\")\n",
    "print()\n",
    "\n",
    "c = a ** 2\n",
    "# print(f\"【c】 shape = {c.shape}\")\n",
    "print(f\"【c】 =\\n{c}\")\n",
    "print()\n",
    "\n",
    "c = a ** (0.5)\n",
    "# print(f\"【c】 shape = {c.shape}\")\n",
    "print(f\"【c】 =\\n{c}\")\n",
    "print()\n",
    "\n",
    "c = tf.sqrt(a)\n",
    "# print(f\"【c】 shape = {c.shape}\")\n",
    "print(f\"【c】 =\\n{c}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:27:55.310635Z",
     "iopub.status.busy": "2020-06-16T10:27:55.310195Z",
     "iopub.status.idle": "2020-06-16T10:27:55.327068Z",
     "shell.execute_reply": "2020-06-16T10:27:55.325867Z",
     "shell.execute_reply.started": "2020-06-16T10:27:55.310579Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【a】 =\n",
      "[[ 1.  2.]\n",
      " [-3.  4.]]\n",
      "\n",
      "【c】 =\n",
      "[[False False]\n",
      " [False  True]]\n",
      "\n",
      "【c】 =\n",
      "[[False  True]\n",
      " [False  True]]\n",
      "\n",
      "【c】 =\n",
      "[[ True  True]\n",
      " [ True  True]]\n",
      "\n",
      "【c】 =\n",
      "[[False  True]\n",
      " [False False]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 逻辑运算\n",
    "\n",
    "# print(f\"【a】 shape = {a.shape}\")\n",
    "print(f\"【a】 =\\n{a}\")\n",
    "print()\n",
    "\n",
    "c = (a > 2)\n",
    "# print(f\"【c】 shape = {c.shape}\")\n",
    "print(f\"【c】 =\\n{c}\")\n",
    "print()\n",
    "\n",
    "c = (a >= 2) & (a <= 4)\n",
    "# print(f\"【c】 shape = {c.shape}\")\n",
    "print(f\"【c】 =\\n{c}\")\n",
    "print()\n",
    "\n",
    "c = (a >= 2) | (a <= 3)\n",
    "# print(f\"【c】 shape = {c.shape}\")\n",
    "print(f\"【c】 =\\n{c}\")\n",
    "print()\n",
    "\n",
    "c = (a == 2)\n",
    "# print(f\"【c】 shape = {c.shape}\")\n",
    "print(f\"【c】 =\\n{c}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:27:56.172771Z",
     "iopub.status.busy": "2020-06-16T10:27:56.172356Z",
     "iopub.status.idle": "2020-06-16T10:27:56.184278Z",
     "shell.execute_reply": "2020-06-16T10:27:56.183202Z",
     "shell.execute_reply.started": "2020-06-16T10:27:56.172715Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([12., 21.], dtype=float32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 其他\n",
    "a = tf.constant([1.0, 8.0])\n",
    "b = tf.constant([5.0, 6.0])\n",
    "c = tf.constant([6.0, 7.0])\n",
    "tf.add_n([a, b, c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:27:57.006016Z",
     "iopub.status.busy": "2020-06-16T10:27:57.005674Z",
     "iopub.status.idle": "2020-06-16T10:27:57.013679Z",
     "shell.execute_reply": "2020-06-16T10:27:57.012633Z",
     "shell.execute_reply.started": "2020-06-16T10:27:57.005970Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([5., 8.], dtype=float32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.maximum(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:27:57.879141Z",
     "iopub.status.busy": "2020-06-16T10:27:57.878713Z",
     "iopub.status.idle": "2020-06-16T10:27:57.887789Z",
     "shell.execute_reply": "2020-06-16T10:27:57.886636Z",
     "shell.execute_reply.started": "2020-06-16T10:27:57.879084Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1., 6.], dtype=float32)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.minimum(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 向量运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:27:59.505011Z",
     "iopub.status.busy": "2020-06-16T10:27:59.504593Z",
     "iopub.status.idle": "2020-06-16T10:27:59.525388Z",
     "shell.execute_reply": "2020-06-16T10:27:59.524296Z",
     "shell.execute_reply.started": "2020-06-16T10:27:59.504957Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorShape([9])\n",
      "sum=45\n",
      "mean=5\n",
      "max=9\n",
      "min=1\n",
      "逐元素连乘=362880\n"
     ]
    }
   ],
   "source": [
    "#向量reduce\n",
    "a = tf.range(1, 10)\n",
    "tf.print(a.shape)\n",
    "tf.print(f\"sum={tf.reduce_sum(a)}\")\n",
    "tf.print(f\"mean={tf.reduce_mean(a)}\")\n",
    "tf.print(f\"max={tf.reduce_max(a)}\")\n",
    "tf.print(f\"min={tf.reduce_min(a)}\")\n",
    "tf.print(f\"逐元素连乘={tf.reduce_prod(a)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:28:00.328869Z",
     "iopub.status.busy": "2020-06-16T10:28:00.328441Z",
     "iopub.status.idle": "2020-06-16T10:28:00.346752Z",
     "shell.execute_reply": "2020-06-16T10:28:00.345647Z",
     "shell.execute_reply.started": "2020-06-16T10:28:00.328811Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "\n",
      "[[6]\n",
      " [15]\n",
      " [24]]\n",
      "\n",
      "[[12 15 18]]\n",
      "\n",
      "[12 15 18]\n"
     ]
    }
   ],
   "source": [
    "#张量指定维度进行reduce\n",
    "b = tf.reshape(a, (3, 3))\n",
    "tf.print(b)\n",
    "print()\n",
    "tf.print(tf.reduce_sum(b, axis=1, keepdims=True))\n",
    "print()\n",
    "tf.print(tf.reduce_sum(b, axis=0, keepdims=True)) \n",
    "print()\n",
    "tf.print(tf.reduce_sum(b, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:28:01.192040Z",
     "iopub.status.busy": "2020-06-16T10:28:01.191529Z",
     "iopub.status.idle": "2020-06-16T10:28:01.203372Z",
     "shell.execute_reply": "2020-06-16T10:28:01.202353Z",
     "shell.execute_reply.started": "2020-06-16T10:28:01.191981Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#bool类型的reduce\n",
    "p = tf.constant([True, False, False])\n",
    "q = tf.constant([False, True, False])\n",
    "\n",
    "tf.print(tf.reduce_all(p))\n",
    "tf.print(tf.reduce_any(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:28:02.057901Z",
     "iopub.status.busy": "2020-06-16T10:28:02.057472Z",
     "iopub.status.idle": "2020-06-16T10:28:02.074674Z",
     "shell.execute_reply": "2020-06-16T10:28:02.073591Z",
     "shell.execute_reply.started": "2020-06-16T10:28:02.057844Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "#利用tf.foldr实现tf.reduce_sum\n",
    "\n",
    "s = tf.foldr(lambda a, b: a + b, a) \n",
    "tf.print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:28:02.915383Z",
     "iopub.status.busy": "2020-06-16T10:28:02.914938Z",
     "iopub.status.idle": "2020-06-16T10:28:02.928716Z",
     "shell.execute_reply": "2020-06-16T10:28:02.927592Z",
     "shell.execute_reply.started": "2020-06-16T10:28:02.915308Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 ... 7 8 9]\n",
      "[1 3 6 ... 28 36 45]\n",
      "[1 2 6 ... 5040 40320 362880]\n"
     ]
    }
   ],
   "source": [
    "#cum扫描累积, 逐元素 累加 / 累乘\n",
    "a = tf.range(1, 10)\n",
    "tf.print(a)\n",
    "tf.print(tf.math.cumsum(a))\n",
    "tf.print(tf.math.cumprod(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:28:03.812497Z",
     "iopub.status.busy": "2020-06-16T10:28:03.812077Z",
     "iopub.status.idle": "2020-06-16T10:28:03.839542Z",
     "shell.execute_reply": "2020-06-16T10:28:03.838542Z",
     "shell.execute_reply.started": "2020-06-16T10:28:03.812443Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 ... 7 8 9]\n",
      "8\n",
      "0\n",
      "\n",
      "[[9 8 9]\n",
      " [2 9 4]\n",
      " [6 9 4]]\n",
      "\n",
      "max val index=[0 1 0]\n",
      "min val index=[1 0 1]\n",
      "\n",
      "max val index=[0 1 1]\n",
      "min val index=[1 0 2]\n"
     ]
    }
   ],
   "source": [
    "#arg 最大 / 最小值 所在位置的索引\n",
    "a = tf.range(1, 10)\n",
    "tf.print(a)\n",
    "tf.print(tf.argmax(a))\n",
    "tf.print(tf.argmin(a))\n",
    "print()\n",
    "\n",
    "a = tf.random.uniform(shape=(3, 3), minval=0, maxval=10, dtype=tf.int32)\n",
    "tf.print(a)\n",
    "print()\n",
    "tf.print(f\"max val index={tf.argmax(a)}\")\n",
    "tf.print(f\"min val index={tf.argmin(a)}\")\n",
    "print()\n",
    "tf.print(f\"max val index={tf.argmax(a, axis=1)}\")\n",
    "tf.print(f\"min val index={tf.argmin(a, axis=1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:28:04.678805Z",
     "iopub.status.busy": "2020-06-16T10:28:04.678378Z",
     "iopub.status.idle": "2020-06-16T10:28:04.691051Z",
     "shell.execute_reply": "2020-06-16T10:28:04.689707Z",
     "shell.execute_reply.started": "2020-06-16T10:28:04.678748Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top k val = [8 7 5]\n",
      "top k val index = [5 2 3]\n"
     ]
    }
   ],
   "source": [
    "#tf.math.top_k可以用于对张量排序\n",
    "a = tf.constant([1, 3, 7, 5, 4, 8])\n",
    "\n",
    "values, indices = tf.math.top_k(a, 3, sorted=True)\n",
    "tf.print(f\"top k val = {values}\")\n",
    "tf.print(f\"top k val index = {indices}\")\n",
    "\n",
    "#利用tf.math.top_k可以在TensorFlow中实现KNN算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 矩阵运算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "矩阵运算包括：\n",
    "- 矩阵乘法\n",
    "- 矩阵转置\n",
    "- 矩阵求逆\n",
    "- 矩阵求迹\n",
    "- 矩阵范数\n",
    "- 矩阵行列式\n",
    "- 矩阵求特征值\n",
    "- 矩阵分解\n",
    "- ...\n",
    "\n",
    "除了一些常用的运算外，大部分和矩阵有关的运算都在 **tf.linalg子包** 中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:28:07.087844Z",
     "iopub.status.busy": "2020-06-16T10:28:07.087436Z",
     "iopub.status.idle": "2020-06-16T10:28:07.105070Z",
     "shell.execute_reply": "2020-06-16T10:28:07.103830Z",
     "shell.execute_reply.started": "2020-06-16T10:28:07.087789Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【a】 shape = (2, 2)\n",
      "【a】 =\n",
      "[[1 3]\n",
      " [5 7]]\n",
      "\n",
      "【b】 shape = (2, 2)\n",
      "【b】 =\n",
      "[[2 4]\n",
      " [6 8]]\n",
      "\n",
      "【c】 shape = (2, 2)\n",
      "【c】 =\n",
      "[[20 28]\n",
      " [52 76]]\n",
      "\n",
      "【c】 shape = (2, 2)\n",
      "【c】 =\n",
      "[[20 28]\n",
      " [52 76]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#矩阵乘法\n",
    "a = tf.constant([[1, 3], [5, 7]])\n",
    "b = tf.constant([[2, 4], [6, 8]])\n",
    "print(f\"【a】 shape = {a.shape}\")\n",
    "print(f\"【a】 =\\n{a}\")\n",
    "print()\n",
    "print(f\"【b】 shape = {b.shape}\")\n",
    "print(f\"【b】 =\\n{b}\")\n",
    "print()\n",
    "\n",
    "c = tf.matmul(a, b)\n",
    "print(f\"【c】 shape = {c.shape}\")\n",
    "print(f\"【c】 =\\n{c}\")\n",
    "print()\n",
    "\n",
    "c = a@b  #等价于tf.matmul(a,b)\n",
    "print(f\"【c】 shape = {c.shape}\")\n",
    "print(f\"【c】 =\\n{c}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:28:07.902463Z",
     "iopub.status.busy": "2020-06-16T10:28:07.902019Z",
     "iopub.status.idle": "2020-06-16T10:28:07.911651Z",
     "shell.execute_reply": "2020-06-16T10:28:07.910218Z",
     "shell.execute_reply.started": "2020-06-16T10:28:07.902404Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "矩阵的zhuanzhi:\n",
      "【c】 shape = (2, 2)\n",
      "【c】 =\n",
      "[[20 52]\n",
      " [28 76]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#矩阵转置\n",
    "c = tf.transpose(c)\n",
    "print(\"矩阵的zhuanzhi:\")\n",
    "print(f\"【c】 shape = {c.shape}\")\n",
    "print(f\"【c】 =\\n{c}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:28:08.700734Z",
     "iopub.status.busy": "2020-06-16T10:28:08.700194Z",
     "iopub.status.idle": "2020-06-16T10:28:08.714635Z",
     "shell.execute_reply": "2020-06-16T10:28:08.713508Z",
     "shell.execute_reply.started": "2020-06-16T10:28:08.700673Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【a】 shape = (2, 2)\n",
      "【a】 =\n",
      "[[1. 2.]\n",
      " [3. 4.]]\n",
      "\n",
      "矩阵求逆:\n",
      "【b】 shape = (2, 2)\n",
      "【b】 =\n",
      "[[-2.0000002   1.0000001 ]\n",
      " [ 1.5000001  -0.50000006]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#矩阵求逆，必须为tf.float32或tf.double类型\n",
    "a = tf.constant([[1.0,  2], [3.0, 4]], dtype = tf.float32)\n",
    "print(f\"【a】 shape = {a.shape}\")\n",
    "print(f\"【a】 =\\n{a}\")\n",
    "print()\n",
    "\n",
    "b = tf.linalg.inv(a)\n",
    "print(\"矩阵求逆:\")\n",
    "print(f\"【b】 shape = {b.shape}\")\n",
    "print(f\"【b】 =\\n{b}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:28:09.553726Z",
     "iopub.status.busy": "2020-06-16T10:28:09.553363Z",
     "iopub.status.idle": "2020-06-16T10:28:09.565256Z",
     "shell.execute_reply": "2020-06-16T10:28:09.564242Z",
     "shell.execute_reply.started": "2020-06-16T10:28:09.553677Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【a】 shape = (2, 2)\n",
      "【a】 =\n",
      "[[1. 2.]\n",
      " [3. 4.]]\n",
      "\n",
      "矩阵求迹:\n",
      "【b】 shape = ()\n",
      "【b】 =\n",
      "5.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#矩阵求迹(trace)\n",
    "a = tf.constant([[1.0, 2], [3, 4]])\n",
    "print(f\"【a】 shape = {a.shape}\")\n",
    "print(f\"【a】 =\\n{a}\")\n",
    "print()\n",
    "\n",
    "b = tf.linalg.trace(a)\n",
    "print(\"矩阵求迹:\")\n",
    "print(f\"【b】 shape = {b.shape}\")\n",
    "print(f\"【b】 =\\n{b}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:28:10.436185Z",
     "iopub.status.busy": "2020-06-16T10:28:10.435734Z",
     "iopub.status.idle": "2020-06-16T10:28:10.449948Z",
     "shell.execute_reply": "2020-06-16T10:28:10.448777Z",
     "shell.execute_reply.started": "2020-06-16T10:28:10.436127Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【a】 shape = (2, 2)\n",
      "【a】 =\n",
      "[[1. 2.]\n",
      " [3. 4.]]\n",
      "\n",
      "矩阵求范数:\n",
      "【b】 shape = ()\n",
      "【b】 =\n",
      "5.4772257804870605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#矩阵求范数\n",
    "a = tf.constant([[1.0, 2], [3, 4]])\n",
    "print(f\"【a】 shape = {a.shape}\")\n",
    "print(f\"【a】 =\\n{a}\")\n",
    "print()\n",
    "\n",
    "b = tf.linalg.norm(a)\n",
    "print(\"矩阵求范数:\")\n",
    "print(f\"【b】 shape = {b.shape}\")\n",
    "print(f\"【b】 =\\n{b}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:28:17.955841Z",
     "iopub.status.busy": "2020-06-16T10:28:17.955242Z",
     "iopub.status.idle": "2020-06-16T10:28:17.970557Z",
     "shell.execute_reply": "2020-06-16T10:28:17.969200Z",
     "shell.execute_reply.started": "2020-06-16T10:28:17.955773Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【a】 shape = (2, 2)\n",
      "【a】 =\n",
      "[[1. 2.]\n",
      " [3. 4.]]\n",
      "\n",
      "矩阵求行列式:\n",
      "【b】 shape = ()\n",
      "【b】 =\n",
      "-2.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#矩阵求行列式\n",
    "a = tf.constant([[1.0, 2], [3, 4]])\n",
    "print(f\"【a】 shape = {a.shape}\")\n",
    "print(f\"【a】 =\\n{a}\")\n",
    "print()\n",
    "\n",
    "b = tf.linalg.det(a)\n",
    "print(\"矩阵求行列式:\")\n",
    "print(f\"【b】 shape = {b.shape}\")\n",
    "print(f\"【b】 =\\n{b}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:28:19.135726Z",
     "iopub.status.busy": "2020-06-16T10:28:19.135281Z",
     "iopub.status.idle": "2020-06-16T10:28:19.148916Z",
     "shell.execute_reply": "2020-06-16T10:28:19.147526Z",
     "shell.execute_reply.started": "2020-06-16T10:28:19.135671Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【a】 shape = (2, 2)\n",
      "【a】 =\n",
      "[[1. 2.]\n",
      " [3. 4.]]\n",
      "\n",
      "矩阵求特征值:\n",
      "【b】 shape = (2,)\n",
      "【b】 =\n",
      "[-0.8541021  5.854102 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#矩阵求特征值\n",
    "a = tf.constant([[1.0, 2], [3, 4]], dtype=tf.float32)\n",
    "print(f\"【a】 shape = {a.shape}\")\n",
    "print(f\"【a】 =\\n{a}\")\n",
    "print()\n",
    "\n",
    "b = tf.linalg.eigvalsh(a)\n",
    "print(\"矩阵求特征值:\")\n",
    "print(f\"【b】 shape = {b.shape}\")\n",
    "print(f\"【b】 =\\n{b}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:28:20.282512Z",
     "iopub.status.busy": "2020-06-16T10:28:20.281994Z",
     "iopub.status.idle": "2020-06-16T10:28:20.339148Z",
     "shell.execute_reply": "2020-06-16T10:28:20.338102Z",
     "shell.execute_reply.started": "2020-06-16T10:28:20.282452Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【a】 shape = (2, 2)\n",
      "【a】 =\n",
      "[[1. 2.]\n",
      " [3. 4.]]\n",
      "\n",
      "矩阵求qr分解:\n",
      "【b】 shape = (2, 2)\n",
      "【b】 =\n",
      "[[-0.3162278  -0.9486833 ]\n",
      " [-0.9486833   0.31622773]]\n",
      "\n",
      "【c】 shape = (2, 2)\n",
      "【c】 =\n",
      "[[-3.1622777  -4.4271884 ]\n",
      " [ 0.         -0.63245535]]\n",
      "\n",
      "【b@c】 shape = (2, 2)\n",
      "【b@c】 =\n",
      "[[1.0000001 1.9999998]\n",
      " [3.        4.       ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#矩阵求qr分解\n",
    "a = tf.constant([[1.0, 2], [3, 4]], dtype=tf.float32)\n",
    "print(f\"【a】 shape = {a.shape}\")\n",
    "print(f\"【a】 =\\n{a}\")\n",
    "print()\n",
    "\n",
    "b, c = tf.linalg.qr(a)\n",
    "print(\"矩阵求qr分解:\")\n",
    "print(f\"【b】 shape = {b.shape}\")\n",
    "print(f\"【b】 =\\n{b}\")\n",
    "print()\n",
    "print(f\"【c】 shape = {c.shape}\")\n",
    "print(f\"【c】 =\\n{c}\")\n",
    "print()\n",
    "\n",
    "d = b @ c\n",
    "print(f\"【b@c】 shape = {d.shape}\")\n",
    "print(f\"【b@c】 =\\n{d}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:28:21.162988Z",
     "iopub.status.busy": "2020-06-16T10:28:21.162616Z",
     "iopub.status.idle": "2020-06-16T10:28:21.184814Z",
     "shell.execute_reply": "2020-06-16T10:28:21.183853Z",
     "shell.execute_reply.started": "2020-06-16T10:28:21.162939Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【a】 shape = (2, 2)\n",
      "【a】 =\n",
      "[[1. 2.]\n",
      " [3. 4.]]\n",
      "\n",
      "矩阵求SVD分解:\n",
      "【v】 shape = (2,)\n",
      "【v】 =\n",
      "[5.4649854  0.36596614]\n",
      "\n",
      "【s】 shape = (2, 2)\n",
      "【s】 =\n",
      "[[ 0.4045535 -0.9145143]\n",
      " [ 0.9145143  0.4045535]]\n",
      "\n",
      "【d】 shape = (2, 2)\n",
      "【d】 =\n",
      "[[ 0.5760484  0.8174156]\n",
      " [ 0.8174156 -0.5760484]]\n",
      "\n",
      "【e】 shape = (2, 2)\n",
      "【e】 =\n",
      "[[0.9999996 1.9999996]\n",
      " [2.9999998 4.       ]]\n",
      "\n",
      "【e】 shape = (2, 2)\n",
      "【e】 =\n",
      "[[0.9999996 1.9999996]\n",
      " [2.9999998 4.       ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#矩阵求SVD分解\n",
    "a = tf.constant([[1.0, 2], [3, 4]], dtype=tf.float32)\n",
    "print(f\"【a】 shape = {a.shape}\")\n",
    "print(f\"【a】 =\\n{a}\")\n",
    "print()\n",
    "\n",
    "v, s, d = tf.linalg.svd(a)\n",
    "print(\"矩阵求SVD分解:\")\n",
    "print(f\"【v】 shape = {v.shape}\")\n",
    "print(f\"【v】 =\\n{v}\")\n",
    "print()\n",
    "print(f\"【s】 shape = {s.shape}\")\n",
    "print(f\"【s】 =\\n{s}\")\n",
    "print()\n",
    "print(f\"【d】 shape = {d.shape}\")\n",
    "print(f\"【d】 =\\n{d}\")\n",
    "print()\n",
    "\n",
    "e = tf.matmul(tf.matmul(s, tf.linalg.diag(v)), d)\n",
    "print(f\"【e】 shape = {e.shape}\")\n",
    "print(f\"【e】 =\\n{e}\")\n",
    "print()\n",
    "e = s @ tf.linalg.diag(v) @ d\n",
    "print(f\"【e】 shape = {e.shape}\")\n",
    "print(f\"【e】 =\\n{e}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 广播机制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow的广播规则和numpy是一样的:\n",
    "\n",
    "1. 若两个张量的维度长度不同，需将维度较小的张量扩展至较大张量的维度长度；\n",
    "2. 若两个张量在某个维度上的长度是相同的，或其中一个张量在该维度上的长度为1，则称两个张量在该维度上是相容的；\n",
    "3. 若两个张量在所有维度上都是相容的，它们就能使用广播机制；\n",
    "4. 将某维度长度较小的张量扩充至较大维度长度，即对维度长度较小的张量，在该维度方向进行复制，只到维度长度一致；\n",
    "5. 广播之后，每个维度的长度将取两个张量在该维度长度的较大值；\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:28:24.682675Z",
     "iopub.status.busy": "2020-06-16T10:28:24.682135Z",
     "iopub.status.idle": "2020-06-16T10:28:24.703815Z",
     "shell.execute_reply": "2020-06-16T10:28:24.702672Z",
     "shell.execute_reply.started": "2020-06-16T10:28:24.682613Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【a】 shape = (3,)\n",
      "【a】 =\n",
      "[1 2 3]\n",
      "\n",
      "【b】 shape = (3, 3)\n",
      "【b】 =\n",
      "[[0 0 0]\n",
      " [1 1 1]\n",
      " [2 2 2]]\n",
      "\n",
      "【c】 shape = (3, 3)\n",
      "【c】 =\n",
      "[[1 2 3]\n",
      " [1 2 3]\n",
      " [1 2 3]]\n",
      "\n",
      "【d】 shape = (3, 3)\n",
      "【d】 =\n",
      "[[1 2 3]\n",
      " [2 3 4]\n",
      " [3 4 5]]\n",
      "\n",
      "【d】 shape = (3, 3)\n",
      "【d】 =\n",
      "[[1 2 3]\n",
      " [2 3 4]\n",
      " [3 4 5]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([1, 2, 3])\n",
    "b = tf.constant([[0, 0, 0], [1, 1, 1], [2, 2, 2]])\n",
    "c = tf.broadcast_to(a, b.shape)\n",
    "print(f\"【a】 shape = {a.shape}\")\n",
    "print(f\"【a】 =\\n{a}\")\n",
    "print()\n",
    "print(f\"【b】 shape = {b.shape}\")\n",
    "print(f\"【b】 =\\n{b}\")\n",
    "print()\n",
    "print(f\"【c】 shape = {c.shape}\")\n",
    "print(f\"【c】 =\\n{c}\")\n",
    "print()\n",
    "\n",
    "d = a + b # 等价于 b + tf.broadcast_to(a,b.shape)\n",
    "print(f\"【d】 shape = {d.shape}\")\n",
    "print(f\"【d】 =\\n{d}\")\n",
    "print()\n",
    "\n",
    "d = b + c\n",
    "print(f\"【d】 shape = {d.shape}\")\n",
    "print(f\"【d】 =\\n{d}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:28:25.434009Z",
     "iopub.status.busy": "2020-06-16T10:28:25.433522Z",
     "iopub.status.idle": "2020-06-16T10:28:25.441517Z",
     "shell.execute_reply": "2020-06-16T10:28:25.440451Z",
     "shell.execute_reply.started": "2020-06-16T10:28:25.433953Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 3])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#计算广播后计算结果的形状，静态形状，TensorShape类型参数\n",
    "tf.broadcast_static_shape(a.shape, b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T10:06:15.404325Z",
     "iopub.status.busy": "2020-06-16T10:06:15.404112Z",
     "iopub.status.idle": "2020-06-16T10:06:15.410415Z",
     "shell.execute_reply": "2020-06-16T10:06:15.409599Z",
     "shell.execute_reply.started": "2020-06-16T10:06:15.404287Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([3, 3], dtype=int32)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#计算广播后计算结果的形状，动态形状，Tensor类型参数\n",
    "c = tf.constant([1, 2, 3])\n",
    "d = tf.constant([[1], [2], [3]])\n",
    "tf.broadcast_dynamic_shape(tf.shape(c), tf.shape(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有三种计算图的构建方式：静态计算图，动态计算图，以及Autograph。\n",
    "\n",
    "TensorFlow 2.0主要使用的是动态计算图和Autograph。\n",
    "\n",
    "动态计算图易于调试，编码效率较高，但执行效率偏低。\n",
    "\n",
    "静态计算图执行效率很高，但较难调试。\n",
    "\n",
    "而Autograph机制可以将动态图转换成静态计算图，兼收执行效率和编码效率之利。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoGraph的机制原理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoGraph编码规范总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 被@tf.function修饰的函数应尽可能使用TensorFlow中的函数而不是Python中的其他函数。例如使用tf.print而不是print，使用tf.range而不是range，使用tf.constant(True)而不是True.\n",
    "\n",
    "2. 避免在@tf.function修饰的函数内部定义tf.Variable.\n",
    "\n",
    "3. 被@tf.function修饰的函数不可修改该函数外部的Python列表或字典等数据结构变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T09:54:54.758390Z",
     "iopub.status.busy": "2020-06-16T09:54:54.758169Z",
     "iopub.status.idle": "2020-06-16T09:54:54.763403Z",
     "shell.execute_reply": "2020-06-16T09:54:54.762564Z",
     "shell.execute_reply.started": "2020-06-16T09:54:54.758360Z"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def np_random():\n",
    "    a = np.random.randn(3, 3)\n",
    "    tf.print(a)\n",
    "\n",
    "@tf.function\n",
    "def tf_random():\n",
    "    a = tf.random.normal((3, 3))\n",
    "    tf.print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T09:54:54.764546Z",
     "iopub.status.busy": "2020-06-16T09:54:54.764330Z",
     "iopub.status.idle": "2020-06-16T09:54:54.889558Z",
     "shell.execute_reply": "2020-06-16T09:54:54.888809Z",
     "shell.execute_reply.started": "2020-06-16T09:54:54.764516Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[ 0.15101921, -0.2215621 , -0.64512452],\n",
      "       [-0.54913958, -0.28498345, -1.51774955],\n",
      "       [-1.80412714,  2.37960607, -1.73565518]])\n",
      "array([[ 0.15101921, -0.2215621 , -0.64512452],\n",
      "       [-0.54913958, -0.28498345, -1.51774955],\n",
      "       [-1.80412714,  2.37960607, -1.73565518]])\n"
     ]
    }
   ],
   "source": [
    "#np_random每次执行都是一样的结果。\n",
    "np_random()\n",
    "np_random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T09:54:54.890807Z",
     "iopub.status.busy": "2020-06-16T09:54:54.890600Z",
     "iopub.status.idle": "2020-06-16T09:54:54.951643Z",
     "shell.execute_reply": "2020-06-16T09:54:54.950911Z",
     "shell.execute_reply.started": "2020-06-16T09:54:54.890779Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.50728667 -0.852984726 -0.784401238]\n",
      " [-0.265477121 0.73242414 0.334128559]\n",
      " [-0.36110726 1.34450936 -2.46136665]]\n",
      "[[-2.63817787 -0.871187329 -0.618899286]\n",
      " [0.102082871 -1.47540987 -1.27701926]\n",
      " [0.0411223136 0.963910043 0.184175834]]\n"
     ]
    }
   ],
   "source": [
    "#tf_random每次执行都会有重新生成随机数。\n",
    "tf_random()\n",
    "tf_random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T09:54:54.952837Z",
     "iopub.status.busy": "2020-06-16T09:54:54.952630Z",
     "iopub.status.idle": "2020-06-16T09:54:55.027512Z",
     "shell.execute_reply": "2020-06-16T09:54:55.026798Z",
     "shell.execute_reply.started": "2020-06-16T09:54:54.952808Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=3.0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 避免在@tf.function修饰的函数内部定义tf.Variable.\n",
    "\n",
    "x = tf.Variable(1.0, dtype=tf.float32)\n",
    "\n",
    "@tf.function\n",
    "def outer_var():\n",
    "    x.assign_add(1.0)\n",
    "    tf.print(x)\n",
    "    return(x)\n",
    "\n",
    "outer_var() \n",
    "outer_var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T09:54:55.028627Z",
     "iopub.status.busy": "2020-06-16T09:54:55.028425Z",
     "iopub.status.idle": "2020-06-16T09:54:55.032968Z",
     "shell.execute_reply": "2020-06-16T09:54:55.032149Z",
     "shell.execute_reply.started": "2020-06-16T09:54:55.028599Z"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def inner_var():\n",
    "    x = tf.Variable(1.0, dtype = tf.float32)\n",
    "    x.assign_add(1.0)\n",
    "    tf.print(x)\n",
    "    return(x)\n",
    "\n",
    "#执行将报错\n",
    "# inner_var()\n",
    "#inner_var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T09:54:55.034047Z",
     "iopub.status.busy": "2020-06-16T09:54:55.033848Z",
     "iopub.status.idle": "2020-06-16T09:54:55.039479Z",
     "shell.execute_reply": "2020-06-16T09:54:55.038802Z",
     "shell.execute_reply.started": "2020-06-16T09:54:55.034019Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(), dtype=float32, numpy=5.0>, <tf.Tensor: shape=(), dtype=float32, numpy=6.0>]\n"
     ]
    }
   ],
   "source": [
    "tensor_list = []\n",
    "\n",
    "#@tf.function #加上这一行切换成Autograph结果将不符合预期！！！\n",
    "def append_tensor(x):\n",
    "    tensor_list.append(x)\n",
    "    return tensor_list\n",
    "\n",
    "append_tensor(tf.constant(5.0))\n",
    "append_tensor(tf.constant(6.0))\n",
    "print(tensor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T09:54:55.040534Z",
     "iopub.status.busy": "2020-06-16T09:54:55.040333Z",
     "iopub.status.idle": "2020-06-16T09:54:55.094584Z",
     "shell.execute_reply": "2020-06-16T09:54:55.093898Z",
     "shell.execute_reply.started": "2020-06-16T09:54:55.040507Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'x:0' shape=() dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "tensor_list = []\n",
    "\n",
    "@tf.function # 加上这一行切换成Autograph结果将不符合预期！！！\n",
    "def append_tensor(x):\n",
    "    tensor_list.append(x)\n",
    "    return tensor_list\n",
    "\n",
    "\n",
    "append_tensor(tf.constant(5.0))\n",
    "append_tensor(tf.constant(6.0))\n",
    "print(tensor_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-16T09:54:55.099260Z",
     "iopub.status.busy": "2020-06-16T09:54:55.099059Z",
     "iopub.status.idle": "2020-06-16T09:54:55.104200Z",
     "shell.execute_reply": "2020-06-16T09:54:55.103562Z",
     "shell.execute_reply.started": "2020-06-16T09:54:55.099233Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 0],\n",
       "       [1, 1, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 0, 1]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.randint(0, high=2, size=(4, 4))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
